import re
import time  # ç¡®ä¿å¯¼å…¥timeæ¨¡å—
import hashlib  # ç”¨äºç”Ÿæˆç¼“å­˜é”®

import numpy as np
import faiss
from abc import ABC, abstractmethod
from typing import List, Optional, Dict
from openai import OpenAI
from sentence_transformers import SentenceTransformer, CrossEncoder

"""
æœ¬æ–‡ä»¶ä¾èµ–å®‰è£…
pip install sentence-transformers faiss-cpu numpy openai
å¦‚æœä½¿ç”¨åœ¨çº¿æ¨¡å‹éœ€è¦é¢å¤–å®‰è£…openaiç­‰å¯¹åº”SDK
"""


class EmbeddingModel(ABC):
    @abstractmethod
    def embed(self, texts: List[str]) -> List[List[float]]:
        pass


class LocalEmbeddingModel(EmbeddingModel):
    def __init__(self, model_path: str):
        self.model = SentenceTransformer(model_path)
        self.cache = {}  # æ·»åŠ ç¼“å­˜å­—å…¸

    def embed(self, texts: List[str]) -> List[List[float]]:
        results = []
        uncached_texts = []
        uncached_indices = []
        
        # æ£€æŸ¥ç¼“å­˜
        for i, text in enumerate(texts):
            # ä½¿ç”¨MD5ç”Ÿæˆç¼“å­˜é”®
            cache_key = hashlib.md5(text.encode('utf-8')).hexdigest()
            if cache_key in self.cache:
                results.append(self.cache[cache_key])
            else:
                uncached_texts.append(text)
                uncached_indices.append(i)
        
        # å¦‚æœæœ‰æœªç¼“å­˜çš„æ–‡æœ¬ï¼Œåˆ™åµŒå…¥
        if uncached_texts:
            embeddings = self.model.encode(uncached_texts, convert_to_tensor=False).tolist()
            
            # æ›´æ–°ç¼“å­˜å¹¶å¡«å……ç»“æœ
            for i, text in enumerate(uncached_texts):
                cache_key = hashlib.md5(text.encode('utf-8')).hexdigest()
                self.cache[cache_key] = embeddings[i]
                results.insert(uncached_indices[i], embeddings[i])
                
        return results


class OnlineEmbeddingModel(EmbeddingModel):
    def __init__(self, model_name: str, api_key: Optional[str] = None, base_url: Optional[str] = None):
        self.model_name = model_name
        self.api_key = api_key
        self.base_url = base_url
        self.cache = {}  # æ·»åŠ åµŒå…¥ç¼“å­˜
        self.cache_hits = 0  # ç¼“å­˜å‘½ä¸­è®¡æ•°
        self.api_calls = 0  # APIè°ƒç”¨è®¡æ•°
        
        # å¢åŠ é…ç½®æ—¥å¿—
        print(f"åˆå§‹åŒ–åµŒå…¥æ¨¡å‹: {model_name}")
        print(f"API URL: {base_url if base_url else 'é»˜è®¤OpenAIåœ°å€'}")
        if api_key and len(api_key) > 10:
            print(f"APIå¯†é’¥: {api_key[:6]}...{api_key[-4:]}")
        else:
            print(f"APIå¯†é’¥: {'æœªè®¾ç½®' if not api_key else 'æ— æ•ˆæ ¼å¼'}")
        
        # åˆ›å»ºå®¢æˆ·ç«¯å¹¶æµ‹è¯•è¿æ¥
        print(f"æ­£åœ¨åˆ›å»ºAPIå®¢æˆ·ç«¯...")
        try:
            # ç¡®ä¿base_urlä¸æ˜¯ç©ºå­—ç¬¦ä¸²
            client_kwargs = {"api_key": self.api_key}
            if self.base_url and isinstance(self.base_url, str) and self.base_url.strip():
                client_kwargs["base_url"] = self.base_url
                print(f"ä½¿ç”¨è‡ªå®šä¹‰APIåŸºç¡€URL: {self.base_url}")
            else:
                print(f"æœªæä¾›æœ‰æ•ˆçš„APIåŸºç¡€URLï¼Œå°†ä½¿ç”¨OpenAIé»˜è®¤æœåŠ¡å™¨")
            
            self.client = OpenAI(**client_kwargs)
            
            # æµ‹è¯•è¿æ¥
            print(f"æ­£åœ¨æµ‹è¯•APIè¿æ¥ï¼Œè¯·ç¨å€™...")
            # æ·»åŠ æ›´æ˜ç¡®çš„çŠ¶æ€ä¿¡æ¯
            print(f"  - è¿æ¥APIæœåŠ¡å™¨: {self.base_url if self.base_url else 'OpenAIé»˜è®¤æœåŠ¡å™¨'}")
            print(f"  - ä½¿ç”¨æ¨¡å‹: {self.model_name}")
            print(f"  - å°è¯•è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨...")
            
            # è®¾ç½®ä¸€ä¸ªè¶…æ—¶ï¼Œé˜²æ­¢é•¿æ—¶é—´é˜»å¡
            import threading
            import time
            
            connection_successful = False
            connection_error = None
            
            def test_connection():
                nonlocal connection_successful, connection_error
                try:
                    self.client.models.list()
                    connection_successful = True
                except Exception as e:
                    connection_error = e
            
            # å¯åŠ¨è¿æ¥æµ‹è¯•çº¿ç¨‹
            thread = threading.Thread(target=test_connection)
            thread.start()
            
            # ç­‰å¾…æœ€å¤š10ç§’
            timeout = 10  # ç§’
            start_time = time.time()
            while thread.is_alive() and time.time() - start_time < timeout:
                print(".", end="", flush=True)
                time.sleep(1)
            
            # æ£€æŸ¥ç»“æœ
            if connection_successful:
                print("\nâœ… APIè¿æ¥æµ‹è¯•æˆåŠŸï¼æœåŠ¡å™¨æ­£å¸¸å“åº”")
            elif connection_error:
                raise connection_error
            else:
                raise TimeoutError("APIè¿æ¥æµ‹è¯•è¶…æ—¶")
                
        except Exception as e:
            error_msg = str(e)
            print(f"\nâš ï¸ APIåˆå§‹åŒ–å¤±è´¥: {error_msg}")
            print(f"è¯·æ£€æŸ¥ä»¥ä¸‹å¯èƒ½çš„é—®é¢˜:")
            print(f"  - APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
            print(f"  - APIæœåŠ¡å™¨æ˜¯å¦å¯è®¿é—®")
            print(f"  - ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
            print(f"ç¨‹åºå°†ç»§ç»­è¿è¡Œï¼Œä½†åµŒå…¥åŠŸèƒ½å¯èƒ½å—é™")
            
            # åˆ›å»ºé»˜è®¤å®¢æˆ·ç«¯ä»¥é¿å…åç»­é”™è¯¯
            try:
                self.client = OpenAI(api_key="sk-dummy-key")
            except Exception:
                # å¦‚æœä»ç„¶å¤±è´¥ï¼Œå°†å®¢æˆ·ç«¯è®¾ä¸ºNone
                self.client = None

    def embed(self, texts: List[str], async_mode: bool = False, timeout: float = 5.0) -> List[List[float]]:
        """
        å°†æ–‡æœ¬åµŒå…¥ä¸ºå‘é‡
        
        Args:
            texts: è¦åµŒå…¥çš„æ–‡æœ¬åˆ—è¡¨
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼ˆä¸é˜»å¡ï¼‰
            timeout: å¼‚æ­¥æ¨¡å¼ä¸‹çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []

        # å¦‚æœä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œä½¿ç”¨çº¿ç¨‹æ± å¤„ç†
        if async_mode:
            return self._async_embed(texts, timeout)
        
        # åŒæ­¥æ¨¡å¼å¤„ç†
        embeddings = []
        for text in texts:
            if not text.strip():
                embeddings.append([])
                continue
                
            # ä½¿ç”¨æ–‡æœ¬çš„MD5å“ˆå¸Œä½œä¸ºç¼“å­˜é”®
            cache_key = hashlib.md5(text.encode('utf-8')).hexdigest()
            
            # æ£€æŸ¥ç¼“å­˜
            if cache_key in self.cache:
                self.cache_hits += 1
                cached_percent = (self.cache_hits / (self.cache_hits + self.api_calls)) * 100 if (self.cache_hits + self.api_calls) > 0 else 0
                print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­: {text[:20]}... (å‘½ä¸­ç‡: {cached_percent:.1f}%)")
                embeddings.append(self.cache[cache_key])
                continue
                
            # ç¼“å­˜æœªå‘½ä¸­ï¼Œéœ€è¦è°ƒç”¨API
            for attempt in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
                try:
                    # æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦å­˜åœ¨
                    if self.client is None:
                        raise ValueError("APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                        
                    # å¢åŠ è¯·æ±‚è°ƒè¯•ä¿¡æ¯
                    print(f"å‘é€åµŒå…¥è¯·æ±‚ (å°è¯• {attempt+1}/3):")
                    print(f"  - æ¨¡å‹: {self.model_name}")
                    print(f"  - æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
                    
                    response = self.client.embeddings.create(
                        model=self.model_name,
                        input=text,
                        encoding_format="float"
                    )
                    self.api_calls += 1

                    # å¼ºåŒ–å“åº”æ ¡éªŒ
                    if not response or not response.data:
                        raise ValueError("APIè¿”å›ç©ºå“åº”")

                    embedding = response.data[0].embedding
                    if not isinstance(embedding, list) or len(embedding) == 0:
                        raise ValueError("æ— æ•ˆçš„åµŒå…¥æ ¼å¼")

                    print(f"âœ… åµŒå…¥æˆåŠŸï¼Œå‘é‡ç»´åº¦: {len(embedding)}")
                    
                    # ç¼“å­˜ç»“æœ
                    self.cache[cache_key] = embedding
                    embeddings.append(embedding)
                    break
                except Exception as e:
                    error_msg = str(e)
                    print(f"âŒ åµŒå…¥å°è¯• {attempt+1} å¤±è´¥: {error_msg}")
                    
                    if "rate limit" in error_msg.lower():
                        print("   APIé€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…æ—¶é—´å»¶é•¿")
                        time.sleep(5)  # é€Ÿç‡é™åˆ¶æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
                    
                    if attempt == 2:
                        print(f"âš ï¸ åµŒå…¥æœ€ç»ˆå¤±è´¥ï¼ˆå·²é‡è¯•3æ¬¡ï¼‰: {error_msg}")
                        # ä½¿ç”¨é›¶å‘é‡ä»£æ›¿ï¼Œç»´åº¦ä½¿ç”¨å¸¸è§çš„åµŒå…¥ç»´åº¦
                        if self.model_name == "text-embedding-ada-002":
                            dim = 1536  # Ada-002çš„ç»´åº¦
                        elif "text-embedding-3" in self.model_name:
                            dim = 3072 if "large" in self.model_name else 1536  # æ–°æ¨¡å‹çš„ç»´åº¦
                        else:
                            dim = 1024  # é»˜è®¤ç»´åº¦
                            
                        embeddings.append([0.0] * dim)
                    time.sleep(1)  # é‡è¯•é—´éš”
        return embeddings
    
    def _async_embed(self, texts: List[str], timeout: float = 5.0) -> List[List[float]]:
        """
        å¼‚æ­¥æ–¹å¼å¤„ç†åµŒå…¥ï¼Œè®¾ç½®è¶…æ—¶æœºåˆ¶
        
        Args:
            texts: è¦åµŒå…¥çš„æ–‡æœ¬åˆ—è¡¨
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        import concurrent.futures
        
        if not texts:
            return []
        
        # åˆ›å»ºç»“æœåˆ—è¡¨å¹¶é¢„å¡«å……
        # æ¯ä¸ªä½ç½®å¯¹åº”ä¸€ä¸ªé›¶å‘é‡ï¼Œç»´åº¦æ ¹æ®æ¨¡å‹ç¡®å®š
        default_dim = 1536  # é»˜è®¤ç»´åº¦
        if self.model_name == "text-embedding-ada-002":
            default_dim = 1536
        elif "text-embedding-3" in self.model_name:
            default_dim = 3072 if "large" in self.model_name else 1536
            
        results = [[0.0] * default_dim for _ in range(len(texts))]
        
        # å®šä¹‰å•ä¸ªæ–‡æœ¬çš„åµŒå…¥å‡½æ•°
        def _embed_single_text(idx, text):
            if not text.strip():
                return idx, []
                
            # ä½¿ç”¨æ–‡æœ¬çš„MD5å“ˆå¸Œä½œä¸ºç¼“å­˜é”®
            cache_key = hashlib.md5(text.encode('utf-8')).hexdigest()
            
            # æ£€æŸ¥ç¼“å­˜
            if cache_key in self.cache:
                self.cache_hits += 1
                print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­: {text[:20]}...")
                return idx, self.cache[cache_key]
            
            # å°è¯•APIè°ƒç”¨
            for attempt in range(3):
                try:
                    if self.client is None:
                        raise ValueError("APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                        
                    print(f"[å¼‚æ­¥] å‘é€åµŒå…¥è¯·æ±‚ (å°è¯• {attempt+1}/3):")
                    print(f"  - æ¨¡å‹: {self.model_name}")
                    print(f"  - æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
                    
                    response = self.client.embeddings.create(
                        model=self.model_name,
                        input=text,
                        encoding_format="float"
                    )
                    self.api_calls += 1
                    
                    if not response or not response.data:
                        raise ValueError("APIè¿”å›ç©ºå“åº”")
                        
                    embedding = response.data[0].embedding
                    if not isinstance(embedding, list) or len(embedding) == 0:
                        raise ValueError("æ— æ•ˆçš„åµŒå…¥æ ¼å¼")
                        
                    print(f"âœ… [å¼‚æ­¥] åµŒå…¥æˆåŠŸï¼Œå‘é‡ç»´åº¦: {len(embedding)}")
                    
                    # ç¼“å­˜ç»“æœ
                    self.cache[cache_key] = embedding
                    return idx, embedding
                    
                except Exception as e:
                    error_msg = str(e)
                    print(f"âŒ [å¼‚æ­¥] åµŒå…¥å°è¯• {attempt+1} å¤±è´¥: {error_msg}")
                    
                    if "rate limit" in error_msg.lower():
                        time.sleep(3)  # é€Ÿç‡é™åˆ¶æ—¶ç­‰å¾…
                        
                    if attempt < 2:  # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        time.sleep(1)  # çŸ­æš‚ç­‰å¾…åé‡è¯•
            
            # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é›¶å‘é‡
            print(f"âš ï¸ [å¼‚æ­¥] æ‰€æœ‰åµŒå…¥å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é›¶å‘é‡")
            return idx, [0.0] * default_dim
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_idx = {executor.submit(_embed_single_text, i, text): i 
                             for i, text in enumerate(texts)}
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in concurrent.futures.as_completed(future_to_idx, timeout=timeout):
                try:
                    idx, embedding = future.result()
                    results[idx] = embedding
                except Exception as e:
                    print(f"âš ï¸ [å¼‚æ­¥] è·å–åµŒå…¥ç»“æœæ—¶å‡ºé”™: {str(e)}")
        
        return results
    
    def get_cache_stats(self):
        """è¿”å›ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total = self.cache_hits + self.api_calls
        hit_rate = (self.cache_hits / total) * 100 if total > 0 else 0
        return {
            "cache_size": len(self.cache),
            "cache_hits": self.cache_hits,
            "api_calls": self.api_calls,
            "hit_rate_percent": hit_rate
        }
        
    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        cache_size = len(self.cache)
        self.cache.clear()
        return f"å·²æ¸…é™¤ {cache_size} æ¡ç¼“å­˜åµŒå…¥"


class HybridEmbeddingModel(EmbeddingModel):
    """
    æ··åˆåµŒå…¥æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨APIæ¨¡å‹ï¼Œå¦‚æœAPIæ¨¡å‹å¤±è´¥åˆ™ä½¿ç”¨æœ¬åœ°æ¨¡å‹ã€‚
    å…è®¸ç”¨æˆ·é€‰æ‹©æ˜¯å¦ä¸‹è½½æœ¬åœ°å¤‡ç”¨æ¨¡å‹ï¼Œå¹¶æ ¹æ®ç”¨æˆ·é€‰æ‹©å’Œä¸‹è½½ç»“æœè°ƒæ•´æ¨¡å‹ä½¿ç”¨ç­–ç•¥ã€‚
    
    å‚æ•°:
        api_model: APIåµŒå…¥æ¨¡å‹å®ä¾‹
        local_model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„
        local_model_enabled: æ˜¯å¦å¯ç”¨æœ¬åœ°æ¨¡å‹
    """
    def __init__(self, api_model: OnlineEmbeddingModel, local_model_path: str = "paraphrase-multilingual-MiniLM-L12-v2", 
                 local_model_enabled: bool = False):
        self.api_model = api_model
        self.local_model = None
        self.local_model_path = local_model_path
        self.local_model_failed = False
        self.use_local_model = False
        self.cache = {}  # æ·»åŠ ç¼“å­˜å­—å…¸
        
        # æ£€æŸ¥APIè¿æ¥çŠ¶æ€
        api_connected = False
        if hasattr(api_model, 'client') and api_model.client is not None:
            try:
                print("æ­£åœ¨æµ‹è¯•APIè¿æ¥çŠ¶æ€...")
                # å…ˆæ£€æŸ¥clientæ˜¯å¦æœ‰modelså±æ€§
                if hasattr(api_model.client, 'models'):
                    # è®¾ç½®è¿æ¥æµ‹è¯•è¶…æ—¶
                    import threading
                    import time
                    
                    connection_successful = False
                    connection_error = None
                    
                    def test_connection():
                        nonlocal connection_successful, connection_error
                        try:
                            api_model.client.models.list()
                            connection_successful = True
                        except Exception as e:
                            connection_error = e
                    
                    # å¯åŠ¨è¿æ¥æµ‹è¯•çº¿ç¨‹
                    thread = threading.Thread(target=test_connection)
                    thread.start()
                    
                    # ç­‰å¾…æœ€å¤š10ç§’
                    timeout = 10  # ç§’
                    start_time = time.time()
                    while thread.is_alive() and time.time() - start_time < timeout:
                        print(".", end="", flush=True)
                        time.sleep(1)
                    
                    # æ£€æŸ¥ç»“æœ
                    if connection_successful:
                        api_connected = True
                        print("\nAPIè¿æ¥æµ‹è¯•å®Œæˆ")
                    elif connection_error:
                        print(f"\nAPIè¿æ¥æµ‹è¯•å¤±è´¥: {str(connection_error)}")
                    else:
                        print("\nAPIè¿æ¥æµ‹è¯•è¶…æ—¶")
                else:
                    print("APIå®¢æˆ·ç«¯ä¸åŒ…å«modelså±æ€§ï¼Œå¯èƒ½åˆå§‹åŒ–ä¸å®Œæ•´")
            except Exception as e:
                api_connected = False
                print(f"APIè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
        
        # æ‰“å°åˆå§‹åŒ–ä¿¡æ¯
        print("\n" + "="*80)
        print("ã€åµŒå…¥æ¨¡å‹åˆå§‹åŒ–ã€‘".center(60))
        print("="*80)
        print(f"APIåµŒå…¥æ¨¡å‹å·²åˆå§‹åŒ–: {api_model.model_name}")
        
        if api_connected:
            print("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ")
        else:
            print("âš ï¸ APIè¿æ¥æµ‹è¯•å¤±è´¥")
        
        # æ ¹æ®local_model_enabledå†³å®šæ˜¯å¦åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹
        if local_model_enabled:
            print("\næœ¬åœ°æ¨¡å‹å·²å¯ç”¨ï¼Œæ­£åœ¨åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹...")
            self._initialize_local_model()
        else:
            print("\næœ¬åœ°æ¨¡å‹æœªå¯ç”¨ï¼Œå°†ä»…ä½¿ç”¨APIæ¨¡å‹")
            self.local_model_failed = True
            
        print("\n" + "="*80)
        print(f"åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {'API + æœ¬åœ°å¤‡ç”¨' if self.use_local_model else 'API' }")
        print("="*80 + "\n")
    
    def _initialize_local_model(self):
        """åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹"""
        print(f"\nå¼€å§‹åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹: '{self.local_model_path}'")
        print("åˆå§‹åŒ–è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        try:
            # è®¾ç½®åˆå§‹åŒ–è¶…æ—¶å’Œæ¨¡å‹å¤§å°ä¼°è®¡
            import time
            import threading
            import sys
            
            start_time = time.time()
            init_started = False
            init_completed = False
            init_error = None
            
            # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºçº¿ç¨‹
            def show_progress():
                spinner = ['â£¾', 'â£½', 'â£»', 'â¢¿', 'â¡¿', 'â£Ÿ', 'â£¯', 'â£·']
                spinner_idx = 0
                elapsed_time = 0
                
                while not (init_completed or init_error):
                    if init_started:
                        # æ˜¾ç¤ºè¿›åº¦åŠ¨ç”»
                        elapsed_time = time.time() - start_time
                        sys.stdout.write(f"\råˆå§‹åŒ–ä¸­... {spinner[spinner_idx]} å·²ç”¨æ—¶: {elapsed_time:.1f}ç§’")
                        sys.stdout.flush()
                        spinner_idx = (spinner_idx + 1) % len(spinner)
                    time.sleep(0.1)
            
            # å¯åŠ¨è¿›åº¦æ˜¾ç¤ºçº¿ç¨‹
            progress_thread = threading.Thread(target=show_progress)
            progress_thread.daemon = True
            progress_thread.start()
            
            # åˆ›å»ºåˆå§‹åŒ–çº¿ç¨‹
            def init_model():
                nonlocal init_started, init_completed, init_error
                try:
                    init_started = True
                    # å°è¯•åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹
                    self.local_model = LocalEmbeddingModel(self.local_model_path)
                    init_completed = True
                except Exception as e:
                    init_error = e
            
            # å¯åŠ¨åˆå§‹åŒ–çº¿ç¨‹
            init_thread = threading.Thread(target=init_model)
            init_thread.start()
            
            # ç­‰å¾…åˆå§‹åŒ–å®Œæˆæˆ–è¶…æ—¶
            max_wait_time = 300  # æœ€å¤šç­‰å¾…5åˆ†é’Ÿ
            while init_thread.is_alive() and time.time() - start_time < max_wait_time:
                time.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡çŠ¶æ€
            
            # æ£€æŸ¥åˆå§‹åŒ–ç»“æœ
            if init_completed:
                init_time = time.time() - start_time
                sys.stdout.write("\r" + " " * 50 + "\r")  # æ¸…é™¤è¿›åº¦è¡Œ
                print(f"\nâœ… æœ¬åœ°æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ! ç”¨æ—¶: {init_time:.1f}ç§’")
                print(f"æ¨¡å‹å·²åŠ è½½åˆ°å†…å­˜ï¼Œå°†åœ¨APIè°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨")
                self.use_local_model = True
            elif init_error:
                sys.stdout.write("\r" + " " * 50 + "\r")  # æ¸…é™¤è¿›åº¦è¡Œ
                print(f"\nâŒ æœ¬åœ°æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(init_error)}")
                print("è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®")
                print("ç³»ç»Ÿå°†ä»…ä½¿ç”¨APIæ¨¡å‹")
                self.local_model_failed = True
            else:
                sys.stdout.write("\r" + " " * 50 + "\r")  # æ¸…é™¤è¿›åº¦è¡Œ
                print(f"\nâŒ æœ¬åœ°æ¨¡å‹åˆå§‹åŒ–è¶…æ—¶ï¼ˆè¶…è¿‡{max_wait_time/60:.1f}åˆ†é’Ÿï¼‰")
                print("è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„å’Œç³»ç»Ÿèµ„æº")
                print("ç³»ç»Ÿå°†ä»…ä½¿ç”¨APIæ¨¡å‹")
                self.local_model_failed = True
                
        except Exception as e:
            print(f"\nâŒ æœ¬åœ°æ¨¡å‹åˆå§‹åŒ–è¿‡ç¨‹å‡ºé”™: {str(e)}")
            print("è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„å’Œç³»ç»Ÿèµ„æº")
            print("ç³»ç»Ÿå°†ä»…ä½¿ç”¨APIæ¨¡å‹")
            self.local_model_failed = True

    def embed(self, texts: List[str], async_mode: bool = False, timeout: float = 5.0) -> List[List[float]]:
        """
        åµŒå…¥æ–‡æœ¬ï¼Œæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥æ¨¡å¼
        
        Args:
            texts: è¦åµŒå…¥çš„æ–‡æœ¬åˆ—è¡¨
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼ˆä¸é˜»å¡ï¼‰
            timeout: å¼‚æ­¥æ¨¡å¼ä¸‹çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []
        
        # å¼‚æ­¥æ¨¡å¼ä¼˜å…ˆä½¿ç”¨APIæ¨¡å‹çš„å¼‚æ­¥åµŒå…¥
        if async_mode:
            try:
                # ä½¿ç”¨å¼‚æ­¥æ¨¡å¼è°ƒç”¨APIæ¨¡å‹
                print(f"ä½¿ç”¨å¼‚æ­¥æ¨¡å¼åµŒå…¥ {len(texts)} ä¸ªæ–‡æœ¬...")
                return self.api_model.embed(texts, async_mode=True, timeout=timeout)
            except Exception as e:
                print(f"å¼‚æ­¥åµŒå…¥å¤±è´¥: {str(e)}")
                # è¿”å›é»˜è®¤é›¶å‘é‡
                default_dim = 1536
                return [[0.0] * default_dim for _ in range(len(texts))]
            
        # åŒæ­¥æ¨¡å¼
        results = []
        for text in texts:
            if not text.strip():
                results.append([])
                continue
                
            # ä½¿ç”¨æ–‡æœ¬çš„MD5å“ˆå¸Œä½œä¸ºç¼“å­˜é”®
            cache_key = hashlib.md5(text.encode('utf-8')).hexdigest()
            
            # æ£€æŸ¥ç¼“å­˜
            if cache_key in self.cache:
                print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­: {text[:20]}...")
                results.append(self.cache[cache_key])
                continue
                
            # ä¼˜å…ˆä½¿ç”¨APIæ¨¡å‹ (æœ€å¤š3æ¬¡å°è¯•ï¼ŒåŒ…æ‹¬ç¬¬ä¸€æ¬¡)
            api_success = False
            api_error = None
            
            for attempt in range(3):
                try:
                    if attempt > 0:
                        print(f"APIåµŒå…¥é‡è¯• ({attempt}/2)...")
                    embedding = self.api_model.embed([text])[0]
                    self.cache[cache_key] = embedding
                    results.append(embedding)
                    api_success = True
                    break
                except Exception as e:
                    api_error = e
                    print(f"âŒ APIåµŒå…¥{'' if attempt == 0 else 'é‡è¯•'}å¤±è´¥: {str(e)}")
                    # çŸ­æš‚ç­‰å¾…åé‡è¯•
                    if attempt < 2:  # åªåœ¨å‰ä¸¤æ¬¡å¤±è´¥åç­‰å¾…
                        import time
                        time.sleep(1)
            
            # å¦‚æœAPIè°ƒç”¨æˆåŠŸï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡æœ¬
            if api_success:
                continue
                
            # APIè°ƒç”¨å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            if self.local_model_failed:
                print(f"âš ï¸ APIåµŒå…¥å¤±è´¥ä¸”æœ¬åœ°æ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨é›¶å‘é‡")
                # ä½¿ç”¨é›¶å‘é‡ä»£æ›¿
                dim = 1536  # é»˜è®¤ç»´åº¦
                results.append([0.0] * dim)
                continue
            
            # å°è¯•ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            try:
                print(f"å°è¯•ä½¿ç”¨æœ¬åœ°å¤‡ç”¨æ¨¡å‹è¿›è¡ŒåµŒå…¥...")
                embedding = self.local_model.embed([text])[0]
                print(f"âœ… æœ¬åœ°æ¨¡å‹åµŒå…¥æˆåŠŸ")
                self.cache[cache_key] = embedding
                results.append(embedding)
            except Exception as local_error:
                print(f"âŒ æœ¬åœ°æ¨¡å‹åµŒå…¥ä¹Ÿå¤±è´¥: {str(local_error)}")
                # æ ‡è®°æœ¬åœ°æ¨¡å‹ä¸ºä¸å¯ç”¨
                self.local_model_failed = True
                print(f"âš ï¸ æœ¬åœ°æ¨¡å‹å·²è¢«æ ‡è®°ä¸ºä¸å¯ç”¨ï¼Œä»Šåå°†ä¸å†å°è¯•")
                # ä½¿ç”¨é›¶å‘é‡ä»£æ›¿
                dim = 1536  # é»˜è®¤ç»´åº¦
                results.append([0.0] * dim)
        
        return results
    
    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        cache_size = len(self.cache)
        self.cache.clear()
        return f"å·²æ¸…é™¤ {cache_size} æ¡ç¼“å­˜åµŒå…¥"


class ReRanker(ABC):
    @abstractmethod
    def rerank(self, query: str, documents: List[str]) -> List[float]:
        pass


class CrossEncoderReRanker(ReRanker):
    def __init__(self, model_path: str):
        self.model = CrossEncoder(model_path)

    def rerank(self, query: str, documents: List[str]) -> List[float]:
        pairs = [[query, doc] for doc in documents]
        return self.model.predict(pairs).tolist()


class OnlineCrossEncoderReRanker(ReRanker):
    def __init__(self, model_name: str, api_key: Optional[str] = None, base_url: Optional[str] = None):
        self.model_name = model_name
        self.client = OpenAI(api_key=api_key, base_url=base_url)

    def rerank(self, query: str, documents: List[str]) -> List[float]:
        scores = []
        for doc in documents:
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system",
                         "content": "æ‚¨æ˜¯ä¸€ä¸ªå¸®åŠ©è¯„ä¼°æ–‡æ¡£ä¸æŸ¥è¯¢ç›¸å…³æ€§çš„åŠ©æ‰‹ã€‚è¯·ä»…è¿”å›ä¸€ä¸ª0åˆ°1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡æœ¬ã€‚"},
                        {"role": "user", "content": f"æŸ¥è¯¢ï¼š{query}\næ–‡æ¡£ï¼š{doc}\nè¯·è¯„ä¼°è¯¥æ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§åˆ†æ•°ï¼ˆ0-1ï¼‰ï¼š"}
                    ]
                )
                content = response.choices[0].message.content.strip()
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ•°å€¼
                match = re.search(r"0?\.\d+|\d\.?\d*", content)
                if match:
                    score = float(match.group())
                    score = max(0.0, min(1.0, score))  # ç¡®ä¿åˆ†æ•°åœ¨0-1ä¹‹é—´
                else:
                    score = 0.0  # è§£æå¤±è´¥é»˜è®¤å€¼
            except Exception as e:
                score = 0.0  # å¼‚å¸¸å¤„ç†
            scores.append(score)
        return scores


class RAG:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None or not kwargs.get('singleton', True):
            cls._instance = super(RAG, cls).__new__(cls)
        return cls._instance

    def __init__(self,
                 embedding_model: EmbeddingModel = None,
                 reranker: Optional[ReRanker] = None,
                 singleton: bool = True
                 ):
        if not hasattr(self, 'initialized'):
            self.embedding_model = embedding_model
            self.reranker = reranker
            self.index = None
            self.documents = []
            self.initialized = True

    def initialize_index(self, dim: int = 1024):
        """æ˜¾å¼åˆå§‹åŒ–ç´¢å¼•ï¼Œé˜²æ­¢ç©ºæŒ‡é’ˆå¼‚å¸¸"""
        if self.index is None:
            self.index = faiss.IndexFlatL2(dim)
            print(f"å·²åˆå§‹åŒ–FAISSç´¢å¼•ï¼Œç»´åº¦: {dim}")

    def add_documents(self, documents=None, texts: List[str] = None):
        """
        æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•ï¼Œç¡®ä¿ä¸é‡å¤æ·»åŠ 
        
        Args:
            documents: æ–‡æ¡£å­—å…¸ {key: value} æˆ–é”®å€¼å¯¹åˆ—è¡¨ [(key1, value1), (key2, value2), ...]
            texts: æ–‡æœ¬åˆ—è¡¨ [text1, text2, ...]
        """
        if not documents and not texts:
            print("æ²¡æœ‰æä¾›ä»»ä½•æ–‡æ¡£")
            return
        
        # è¯¦ç»†è®°å½•è¾“å…¥æƒ…å†µ
        if documents:
            print(f"æ¥æ”¶åˆ°documentså‚æ•°ï¼Œç±»å‹: {type(documents)}")
            if isinstance(documents, dict):
                print(f"å­—å…¸åŒ…å« {len(documents)} ä¸ªé”®å€¼å¯¹")
            elif isinstance(documents, list):
                print(f"åˆ—è¡¨åŒ…å« {len(documents)} ä¸ªé¡¹ç›®")
                for i, item in enumerate(documents[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªï¼Œé¿å…æ—¥å¿—è¿‡é•¿
                    print(f"  ç¤ºä¾‹é¡¹ç›®{i+1}: {type(item)}, {str(item)[:50]}...")
        if texts:
            print(f"æ¥æ”¶åˆ°textså‚æ•°ï¼ŒåŒ…å« {len(texts)} ä¸ªæ–‡æœ¬")
            for i, text in enumerate(texts[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"  ç¤ºä¾‹æ–‡æœ¬{i+1}: {text[:50]}...")
        
        # å‡†å¤‡è¦æ·»åŠ çš„æ–‡æœ¬
        new_texts = []
        skipped_texts = []
        
        # å¤„ç†æ–‡æ¡£å‚æ•° - æ”¯æŒå­—å…¸æˆ–é”®å€¼å¯¹åˆ—è¡¨
        if documents:
            if hasattr(documents, 'items'):  # å­—å…¸ç±»å‹
                for key, value in documents.items():
                    print(f"æ£€æŸ¥é”®å€¼å¯¹ - é”®: {key[:30]}..., å€¼: {value[:30]}...")
                    
                    # æ£€æŸ¥é”®æ˜¯å¦é‡å¤
                    if key in self.documents:
                        print(f"  è·³è¿‡é‡å¤é”®: {key[:30]}...")
                        skipped_texts.append(key)
                    else:
                        print(f"  æ·»åŠ æ–°é”®: {key[:30]}...")
                        new_texts.append(key)
                    
                    # æ£€æŸ¥å€¼æ˜¯å¦é‡å¤
                    if value in self.documents:
                        print(f"  è·³è¿‡é‡å¤å€¼: {value[:30]}...")
                        skipped_texts.append(value)
                    else:
                        print(f"  æ·»åŠ æ–°å€¼: {value[:30]}...")
                        new_texts.append(value)
                    
            elif isinstance(documents, list):  # é”®å€¼å¯¹åˆ—è¡¨æˆ–æ™®é€šåˆ—è¡¨
                for item in documents:
                    if isinstance(item, tuple) and len(item) == 2:
                        key, value = item
                        print(f"æ£€æŸ¥é”®å€¼å¯¹ - é”®: {key[:30]}..., å€¼: {value[:30]}...")
                        
                        # ä½¿ç”¨å’Œä¸Šé¢ç›¸åŒçš„æ£€æŸ¥é€»è¾‘
                        if key in self.documents:
                            print(f"  è·³è¿‡é‡å¤é”®: {key[:30]}...")
                            skipped_texts.append(key)
                        else:
                            print(f"  æ·»åŠ æ–°é”®: {key[:30]}...")
                            new_texts.append(key)
                        
                        if value in self.documents:
                            print(f"  è·³è¿‡é‡å¤å€¼: {value[:30]}...")
                            skipped_texts.append(value)
                        else:
                            print(f"  æ·»åŠ æ–°å€¼: {value[:30]}...")
                            new_texts.append(value)
                    else:
                        # å•é¡¹æ–‡æ¡£ï¼Œä¸æ˜¯é”®å€¼å¯¹
                        text = str(item)
                        print(f"æ£€æŸ¥å•é¡¹: {text[:50]}...")
                        if text in self.documents:
                            print(f"  è·³è¿‡é‡å¤é¡¹: {text[:30]}...")
                            skipped_texts.append(text)
                        else:
                            print(f"  æ·»åŠ æ–°é¡¹: {text[:30]}...")
                            new_texts.append(text)
            else:
                print(f"ä¸æ”¯æŒçš„documentsç±»å‹: {type(documents)}")
                raise ValueError(f"documentså‚æ•°å¿…é¡»æ˜¯å­—å…¸æˆ–åˆ—è¡¨ï¼Œæ”¶åˆ°: {type(documents)}")
        
        # å¤„ç†åˆ—è¡¨å½¢å¼çš„æ–‡æ¡£
        if texts:
            for text in texts:
                print(f"æ£€æŸ¥æ–‡æœ¬: {text[:50]}...")
                if text in self.documents:
                    print(f"  è·³è¿‡é‡å¤æ–‡æœ¬: {text[:30]}...")
                    skipped_texts.append(text)
                else:
                    print(f"  æ·»åŠ æ–°æ–‡æœ¬: {text[:30]}...")
                    new_texts.append(text)
        
        # å¦‚æœæ²¡æœ‰æ–°æ–‡æ¡£ï¼Œç›´æ¥è¿”å›
        if not new_texts:
            print(f"æ²¡æœ‰æ–°æ–‡æ¡£éœ€è¦æ·»åŠ ï¼Œå·²è·³è¿‡ {len(skipped_texts)} ä¸ªé‡å¤æ–‡æ¡£")
            return
        
        # å¯¹æ–‡æ¡£è¿›è¡Œå»é‡
        print(f"åˆæ­¥æ”¶é›†äº† {len(new_texts)} ä¸ªæ–°æ–‡æ¡£ï¼Œè¿›è¡Œå†…éƒ¨å»é‡...")
        unique_texts = []
        seen = set()
        for text in new_texts:
            normalized = re.sub(r'\s+', '', text.lower())
            normalized = re.sub(r'[^\w\s]', '', normalized)
            
            if normalized not in seen:
                seen.add(normalized)
                unique_texts.append(text)
            else:
                print(f"  å†…éƒ¨å»é‡: è·³è¿‡ {text[:30]}...")
                skipped_texts.append(text)
        
        print(f"å†…éƒ¨å»é‡åå‰©ä½™ {len(unique_texts)} ä¸ªæ–‡æ¡£")
        
        # æ£€æŸ¥ç°æœ‰æ–‡æ¡£é›†åˆ
        current_docs_normals = {re.sub(r'\s+', '', doc.lower()): i 
                             for i, doc in enumerate(self.documents)}
        current_docs_normals = {re.sub(r'[^\w\s]', '', key): val 
                             for key, val in current_docs_normals.items()}
        
        truly_new_texts = []
        for text in unique_texts:
            normalized = re.sub(r'\s+', '', text.lower())
            normalized = re.sub(r'[^\w\s]', '', normalized)
            
            if normalized in current_docs_normals:
                original_doc = self.documents[current_docs_normals[normalized]]
                print(f"  è§„èŒƒåŒ–å»é‡: è·³è¿‡ '{text[:30]}...'ï¼ŒåŒ¹é…å·²æœ‰ '{original_doc[:30]}...'")
                skipped_texts.append(text)
            else:
                truly_new_texts.append(text)
        
        # æœ€ç»ˆæ±‡æ€»
        print(f"æœ€ç»ˆå»é‡ç»Ÿè®¡:")
        print(f"  - åŸå§‹æ–‡æ¡£æ•°: {len(new_texts)} ä¸ª")
        print(f"  - è·³è¿‡é‡å¤: {len(skipped_texts)} ä¸ª")
        print(f"  - å¾…æ·»åŠ æ–°æ–‡æ¡£: {len(truly_new_texts)} ä¸ª")
        
        # å¦‚æœå»é‡åæ²¡æœ‰æ–°æ–‡æ¡£ï¼Œç›´æ¥è¿”å›
        if not truly_new_texts:
            print("å»é‡åæ²¡æœ‰æ–°æ–‡æ¡£éœ€è¦æ·»åŠ ")
            return
        
        print(f"å‡†å¤‡æ·»åŠ  {len(truly_new_texts)} ä¸ªæ–°æ–‡æ¡£åˆ°ç´¢å¼•")
        
        # æ‰“å°éƒ¨åˆ†æ–°æ–‡æ¡£ç¤ºä¾‹
        for i, text in enumerate(truly_new_texts[:3]):
            print(f"  æ–°æ–‡æ¡£ {i+1}: {text[:100]}...")
        
        # ç”ŸæˆåµŒå…¥
        print("å¼€å§‹ç”Ÿæˆæ–‡æ¡£åµŒå…¥...")
        embeddings = self.embedding_model.embed(truly_new_texts)
        if not embeddings or len(embeddings) == 0:
            print("âš ï¸ åµŒå…¥æ¨¡å‹è¿”å›ç©ºå€¼")
            raise ValueError("åµŒå…¥æ¨¡å‹è¿”å›ç©ºå€¼")

        # è½¬æ¢å¹¶æ£€æŸ¥ç»´åº¦
        embeddings = np.array(embeddings, dtype=np.float32)
        print(f"åµŒå…¥ç»´åº¦: {embeddings.shape}")
        
        # åˆå§‹åŒ–æˆ–æ£€æŸ¥ç´¢å¼•ç»´åº¦
        if self.index is None:
            dim = embeddings.shape[1]
            self.index = faiss.IndexFlatL2(dim)
            print(f"åˆå§‹åŒ–FAISSç´¢å¼•ï¼Œç»´åº¦: {dim}")
        elif embeddings.shape[1] != self.index.d:
            print(f"âš ï¸ åµŒå…¥ç»´åº¦ä¸åŒ¹é…: æœŸæœ› {self.index.d}ï¼Œå®é™… {embeddings.shape[1]}")
            raise ValueError(f"åµŒå…¥ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.index.d}ï¼Œå®é™…{embeddings.shape[1]}")

        # æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•
        self.index.add(embeddings)
        self.documents.extend(truly_new_texts)
        
        print(f"ç´¢å¼•æ›´æ–°å®Œæˆï¼Œå½“å‰ç´¢å¼•åŒ…å« {len(self.documents)} ä¸ªæ–‡æ¡£")

    def query(self, query: str, top_k: int = 5, rerank: bool = False, async_mode: bool = False, timeout: float = 5.0) -> List[str]:
        """
        æŸ¥è¯¢ç›¸å…³æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›çš„æœ€å¤§ç»“æœæ•°
            rerank: æ˜¯å¦å¯¹ç»“æœé‡æ’åº
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼ˆä¸é˜»å¡ï¼‰
            timeout: å¼‚æ­¥æ¨¡å¼ä¸‹çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        if not self.documents:
            return []
        
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        try:
            print(f"æ­£åœ¨ä¸ºæŸ¥è¯¢ç”ŸæˆåµŒå…¥å‘é‡: {query[:50]}...")
            query_embedding = self.embedding_model.embed([query], async_mode=async_mode, timeout=timeout)[0]
            
            # æ£€æŸ¥å‘é‡æ˜¯å¦ä¸ºç©º
            if not query_embedding:
                print("âš ï¸ æŸ¥è¯¢åµŒå…¥ç”Ÿæˆå¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ")
                return []
                
            # æœç´¢ç›¸ä¼¼æ–‡æ¡£
            print(f"ä½¿ç”¨åµŒå…¥å‘é‡æœç´¢ç›¸ä¼¼æ–‡æ¡£...")
            D, I = self.index.search(np.array([query_embedding]), min(top_k, len(self.documents)))
            results = [self.documents[i] for i in I[0]]
            
            # ä½¿ç”¨é›†åˆå»é‡
            unique_results = list(set(results))
            
            # å¦‚æœéœ€è¦é‡æ’åº
            if rerank and self.reranker and len(unique_results) > 1:
                print(f"ä½¿ç”¨é‡æ’å™¨å¯¹ {len(unique_results)} ä¸ªç»“æœè¿›è¡Œæ’åº...")
                scores = self.reranker.rerank(query, unique_results)
                scored_results = list(zip(unique_results, scores))
                scored_results.sort(key=lambda x: x[1], reverse=True)
                unique_results = [r[0] for r in scored_results]
            
            print(f"RAGæŸ¥è¯¢: æ‰¾åˆ°{len(unique_results)}æ¡å»é‡ç»“æœï¼Œä»{len(results)}ä¸ªå€™é€‰ç»“æœä¸­")
            return unique_results
            
        except Exception as e:
            print(f"æŸ¥è¯¢è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            print(traceback.format_exc())
            return []

    def deduplicate_documents(self):
        """
        æ¸…ç†ç´¢å¼•ä¸­çš„é‡å¤æ–‡æ¡£
        è¿™å°†é‡å»ºæ•´ä¸ªç´¢å¼•ï¼Œç¡®ä¿æ¯ä¸ªæ–‡æ¡£åªå‡ºç°ä¸€æ¬¡
        """
        if not self.documents:
            print("æ²¡æœ‰æ–‡æ¡£ï¼Œæ— éœ€å»é‡")
            return
        
        print(f"å¼€å§‹å»é‡ï¼Œå½“å‰æ–‡æ¡£æ•°: {len(self.documents)}")
        
        # è·å–å½“å‰æ–‡æ¡£å¹¶åˆ›å»ºè§„èŒƒåŒ–æ˜ å°„
        original_count = len(self.documents)
        
        # æ›´å¼ºçš„è§„èŒƒåŒ–å’Œå»é‡
        unique_docs = []
        seen_normalized = set()
        
        for doc in self.documents:
            # åˆ›å»ºè§„èŒƒåŒ–ç‰ˆæœ¬ï¼ˆç§»é™¤ç©ºæ ¼ã€æ ‡ç‚¹å¹¶è½¬ä¸ºå°å†™ï¼‰
            normalized = re.sub(r'\s+', '', doc.lower())
            normalized = re.sub(r'[^\w\s]', '', normalized)
            
            if normalized not in seen_normalized:
                seen_normalized.add(normalized)
                unique_docs.append(doc)
            else:
                print(f"æ‰¾åˆ°é‡å¤æ–‡æ¡£: {doc[:50]}...")
        
        new_count = len(unique_docs)
        
        if original_count == new_count:
            print("æ²¡æœ‰å‘ç°é‡å¤æ–‡æ¡£")
            return
        
        print(f"å‘ç°{original_count - new_count}ä¸ªé‡å¤æ–‡æ¡£ï¼Œæ­£åœ¨é‡å»ºç´¢å¼•...")
        
        # é‡ç½®å½“å‰ç´¢å¼•å’Œæ–‡æ¡£
        self.documents = []
        if self.index:
            dim = self.index.d
            self.index = faiss.IndexFlatL2(dim)
        
        # é‡æ–°æ·»åŠ å»é‡åçš„æ–‡æ¡£
        for i, doc in enumerate(unique_docs):
            print(f"é‡æ–°æ·»åŠ æ–‡æ¡£ {i+1}/{len(unique_docs)}: {doc[:30]}...")
        
        # ä½¿ç”¨textså‚æ•°æ·»åŠ æ–‡æ¡£
        self.add_documents(texts=unique_docs)
        print(f"ç´¢å¼•é‡å»ºå®Œæˆï¼Œä»{original_count}ä¸ªæ–‡æ¡£å‡å°‘åˆ°{len(self.documents)}ä¸ªå”¯ä¸€æ–‡æ¡£")
