import re
import time  # ç¡®ä¿å¯¼å…¥timeæ¨¡å—
import hashlib  # ç”¨äºç”Ÿæˆç¼“å­˜é”®
import sys
import io
import requests  # æ·»åŠ requestsåº“ç”¨äºç¡…åŸºæµåŠ¨APIè¯·æ±‚
import os  # æ·»åŠ osæ¨¡å—ç”¨äºå¤„ç†ç¯å¢ƒå˜é‡
import logging
import ssl  # æ·»åŠ sslæ¨¡å—ç”¨äºå¤„ç†SSL/TLSé”™è¯¯
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
import numpy as np
import faiss
from abc import ABC, abstractmethod
from typing import List, Optional, Dict, Union
from openai import OpenAI
from sentence_transformers import SentenceTransformer, CrossEncoder
from pathlib import Path
import copy
import json
import yaml
import random
import traceback
from collections import defaultdict
from datetime import datetime
import pickle

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger('main')

# è®¾ç½®ç³»ç»Ÿé»˜è®¤ç¼–ç ä¸ºUTF-8
try:
    # æ£€æŸ¥encodingå±æ€§æ˜¯å¦å­˜åœ¨ï¼Œé¿å…coloramaå†²çª
    if hasattr(sys.stdout, 'encoding') and sys.stdout.encoding != 'utf-8':
        try:
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
            sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
            print("å·²å°†æ ‡å‡†è¾“å‡ºç¼–ç è®¾ç½®ä¸ºUTF-8")
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸ºUTF-8: {str(e)}")
except Exception as e:
    print(f"è­¦å‘Š: æ£€æŸ¥ç¼–ç æ—¶å‡ºé”™: {str(e)}")

# åˆ›å»ºé»˜è®¤å®‰å…¨çš„SSLä¸Šä¸‹æ–‡
def create_secure_ssl_context():
    """åˆ›å»ºä¸€ä¸ªå®‰å…¨ä½†å…¼å®¹æ€§æ›´å¥½çš„SSLä¸Šä¸‹æ–‡ï¼Œç”¨äºè§£å†³SSLè¿æ¥é—®é¢˜"""
    try:
        import ssl
        
        # åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„SSLä¸Šä¸‹æ–‡
        context = ssl.create_default_context()
        
        # ç¦ç”¨è¯ä¹¦éªŒè¯ï¼Œè§£å†³è‡ªç­¾åè¯ä¹¦é—®é¢˜
        context.check_hostname = False
        context.verify_mode = ssl.CERT_NONE
        
        # è®¾ç½®SSLç‰ˆæœ¬å…¼å®¹æ€§
        context.options |= ssl.OP_NO_SSLv2
        context.options |= ssl.OP_NO_SSLv3
        
        # å…è®¸ä½¿ç”¨å¼±å¯†ç å¥—ä»¶ï¼Œæé«˜å…¼å®¹æ€§
        context.set_ciphers('DEFAULT@SECLEVEL=1')
        
        return context
    except Exception as e:
        logger.warning(f"åˆ›å»ºSSLä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}")
        return None

# è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨å¤„ç†å­—ç¬¦ä¸²ï¼Œé¿å…ç¼–ç é—®é¢˜
def safe_str(text, default=""):
    """å®‰å…¨åœ°å¤„ç†å­—ç¬¦ä¸²ï¼Œé¿å…ç¼–ç é—®é¢˜"""
    if text is None:
        return default
    
    if not isinstance(text, str):
        try:
            text = str(text)
        except:
            return default
            
    # å°è¯•å¤„ç†éASCIIå­—ç¬¦
    try:
        # ä¿ç•™åŸå§‹æ–‡æœ¬ï¼Œä¸å†å°è¯•ASCIIè½¬æ¢
        return text
    except Exception:
        # å¦‚æœå‡ºç°ä»»ä½•å¼‚å¸¸ï¼Œè¿”å›å®‰å…¨å­—ç¬¦ä¸²
        try:
            # å°è¯•ç§»é™¤æ‰€æœ‰éASCIIå­—ç¬¦ä½œä¸ºæœ€åæ‰‹æ®µ
            return ''.join(c for c in text if ord(c) < 128)
        except:
            return default

# è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨æ‰“å°ï¼Œé¿å…ç¼–ç é—®é¢˜
def safe_print(text, prefix=""):
    """å®‰å…¨æ‰“å°å‡½æ•°ï¼Œé¿å…ç¼–ç é—®é¢˜"""
    try:
        print(f"{prefix}{text}")
    except Exception as e:
        try:
            print(f"æ‰“å°é”™è¯¯: {str(e)}")
        except:
            pass

# æ·»åŠ è‡ªå®šä¹‰çš„å®‰å…¨è¯·æ±‚å‡½æ•°ï¼Œå¤„ç†SSLé”™è¯¯
def safe_request(url, method="GET", json=None, headers=None, timeout=10, retries=3, ssl_context=None):
    """
    æ‰§è¡Œå®‰å…¨çš„HTTPè¯·æ±‚ï¼ŒåŒ…å«é‡è¯•å’ŒSSLé”™è¯¯å¤„ç†
    
    Args:
        url: è¯·æ±‚URL
        method: è¯·æ±‚æ–¹æ³•ï¼Œé»˜è®¤GET
        json: JSONè¯·æ±‚ä½“
        headers: è¯·æ±‚å¤´
        timeout: è¶…æ—¶æ—¶é—´(ç§’)
        retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        ssl_context: è‡ªå®šä¹‰SSLä¸Šä¸‹æ–‡
        
    Returns:
        (å“åº”å¯¹è±¡, é”™è¯¯ä¿¡æ¯)
    """
    error_msg = None
    session = requests.Session()
    
    # ç¦ç”¨ç¯å¢ƒä»£ç†
    session.trust_env = False
    
    # è®¾ç½®åŸºæœ¬è¯·æ±‚å¤´
    default_headers = {
        "User-Agent": "Mozilla/5.0 KouriChatRAG/1.0",
        "Content-Type": "application/json"
    }
    
    if headers:
        default_headers.update(headers)
    
    # è®¾ç½®SSLé€‰é¡¹    
    if ssl_context:
        try:
            # ä½¿ç”¨è‡ªå®šä¹‰SSLé€‚é…å™¨
            from requests.adapters import HTTPAdapter
            from urllib3.poolmanager import PoolManager
            
            class SSLAdapter(HTTPAdapter):
                def __init__(self, ssl_context=None, **kwargs):
                    self.ssl_context = ssl_context
                    super(SSLAdapter, self).__init__(**kwargs)
                    
                def init_poolmanager(self, connections, maxsize, block=False, **pool_kwargs):
                    self.poolmanager = PoolManager(
                        num_pools=connections,
                        maxsize=maxsize,
                        block=block,
                        ssl_context=self.ssl_context,
                        **pool_kwargs
                    )
                    
            adapter = SSLAdapter(ssl_context=ssl_context)
            session.mount('https://', adapter)
            safe_print(f"å·²ä½¿ç”¨è‡ªå®šä¹‰SSLä¸Šä¸‹æ–‡å¢å¼ºè¯·æ±‚å®‰å…¨æ€§")
        except Exception as e:
            safe_print(f"è­¦å‘Š: è®¾ç½®SSLé€‚é…å™¨å¤±è´¥: {str(e)}")
    
    # æ‰§è¡Œå¸¦é‡è¯•çš„è¯·æ±‚
    for attempt in range(retries):
        try:
            if method.upper() == "GET":
                response = session.get(url, headers=default_headers, timeout=timeout, proxies={}, verify=True)
            else:
                response = session.post(url, json=json, headers=default_headers, timeout=timeout, proxies={}, verify=True)
                
            return response, None
            
        except requests.exceptions.SSLError as e:
            error_msg = f"SSLé”™è¯¯: {str(e)}"
            safe_print(f"âš ï¸ ç¬¬{attempt+1}æ¬¡å°è¯•å¤±è´¥: SSLé”™è¯¯ï¼Œæ­£åœ¨é‡è¯•...")
            # å‡ºç°SSLé”™è¯¯æ—¶ï¼Œæ·»åŠ å»¶è¿Ÿé˜²æ­¢é¢‘ç¹è¯·æ±‚
            time.sleep(1)
            
        except requests.exceptions.ConnectionError as e:
            error_msg = f"è¿æ¥é”™è¯¯: {str(e)}"
            safe_print(f"âš ï¸ ç¬¬{attempt+1}æ¬¡å°è¯•å¤±è´¥: è¿æ¥é”™è¯¯ï¼Œæ­£åœ¨é‡è¯•...")
            time.sleep(1)
            
        except requests.exceptions.Timeout as e:
            error_msg = f"è¯·æ±‚è¶…æ—¶: {str(e)}"
            safe_print(f"âš ï¸ ç¬¬{attempt+1}æ¬¡å°è¯•å¤±è´¥: è¯·æ±‚è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•...")
            time.sleep(1)
            
        except Exception as e:
            error_msg = f"è¯·æ±‚é”™è¯¯: {str(e)}"
            safe_print(f"âš ï¸ ç¬¬{attempt+1}æ¬¡å°è¯•å¤±è´¥: {error_msg}ï¼Œæ­£åœ¨é‡è¯•...")
            time.sleep(1)
    
    return None, error_msg

import numpy as np
import faiss
from abc import ABC, abstractmethod
from typing import List, Optional, Dict, Union
from openai import OpenAI
from sentence_transformers import SentenceTransformer, CrossEncoder

"""
æœ¬æ–‡ä»¶ä¾èµ–å®‰è£…
pip install sentence-transformers faiss-cpu numpy openai
å¦‚æœä½¿ç”¨åœ¨çº¿æ¨¡å‹éœ€è¦é¢å¤–å®‰è£…openaiç­‰å¯¹åº”SDK
"""


class EmbeddingModel(ABC):
    @abstractmethod
    def embed(self, texts: List[str]) -> List[List[float]]:
        pass


class LocalEmbeddingModel(EmbeddingModel):
    def __init__(self, model_path: str):
        self.model = SentenceTransformer(model_path)
        self.cache = {}  # æ·»åŠ ç¼“å­˜å­—å…¸

    def embed(self, texts: List[str]) -> List[List[float]]:
        results = []
        uncached_texts = []
        uncached_indices = []
        
        # æ£€æŸ¥ç¼“å­˜
        for i, text in enumerate(texts):
            # ä½¿ç”¨MD5ç”Ÿæˆç¼“å­˜é”®
            cache_key = hashlib.md5(text.encode('utf-8')).hexdigest()
            if cache_key in self.cache:
                results.append(self.cache[cache_key])
            else:
                uncached_texts.append(text)
                uncached_indices.append(i)
        
        # å¦‚æœæœ‰æœªç¼“å­˜çš„æ–‡æœ¬ï¼Œåˆ™åµŒå…¥
        if uncached_texts:
            embeddings = self.model.encode(uncached_texts, convert_to_tensor=False).tolist()
            
            # æ›´æ–°ç¼“å­˜å¹¶å¡«å……ç»“æœ
            for i, text in enumerate(uncached_texts):
                cache_key = hashlib.md5(text.encode('utf-8')).hexdigest()
                self.cache[cache_key] = embeddings[i]
                results.insert(uncached_indices[i], embeddings[i])
                
        return results


class OnlineEmbeddingModel(EmbeddingModel):
    def __init__(self, model_name: str, api_key: Optional[str] = None, base_url: Optional[str] = None):
        # å¤„ç†å­—å…¸æ ¼å¼çš„model_nameå‚æ•°
        if isinstance(model_name, dict) and 'value' in model_name:
            model_name = model_name['value']
        
        # å¤„ç†å­—å…¸æ ¼å¼çš„base_urlå‚æ•°
        if isinstance(base_url, dict) and 'value' in base_url:
            safe_print(f"API URLæ˜¯å¯¹è±¡æ ¼å¼ï¼Œå€¼ä¸º: {base_url['value']}")
            base_url = base_url['value']
        
        # ç¡®ä¿model_nameæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œä½¿ç”¨å®‰å…¨å­—ç¬¦ä¸²å¤„ç†
        self.model_name = safe_str(model_name, "text-embedding-ada-002")
        self.api_key = api_key
        self.base_url = base_url
        self.api_calls = 0
        self.cache = {}
        self.cache_hits = 0
        
        # åˆ›å»ºå®¢æˆ·ç«¯å¹¶æµ‹è¯•è¿æ¥
        safe_print("æ­£åœ¨åˆ›å»ºAPIå®¢æˆ·ç«¯...")
        try:
            # ç¡®ä¿base_urlä¸æ˜¯ç©ºå­—ç¬¦ä¸²
            client_kwargs = {"api_key": self.api_key}
            if self.base_url and isinstance(self.base_url, str) and self.base_url.strip():
                # ä¸å†è¿›è¡Œé¢å¤–çš„å­—ç¬¦ä¸²å¤„ç†ï¼Œä½¿ç”¨åŸå§‹URL
                client_kwargs["base_url"] = self.base_url.strip()
                safe_print(f"ä½¿ç”¨è‡ªå®šä¹‰APIåŸºç¡€URL: {self.base_url.strip()}")
            else:
                safe_print("æœªæä¾›æœ‰æ•ˆçš„APIåŸºç¡€URLï¼Œå°†ä½¿ç”¨OpenAIé»˜è®¤æœåŠ¡å™¨")
            
            # åˆ›å»ºå®¢æˆ·ç«¯
            self.client = OpenAI(**client_kwargs)
            
        except Exception as e:
            print("âš ï¸ APIåˆå§‹åŒ–å¤±è´¥")
            print("è¯·æ£€æŸ¥ä»¥ä¸‹å¯èƒ½çš„é—®é¢˜:")
            print("  - APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
            print("  - APIæœåŠ¡å™¨æ˜¯å¦å¯è®¿é—®")
            print("  - ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
            # ä½¿ç”¨æ›´é€šç”¨çš„é”™è¯¯æ¶ˆæ¯ï¼Œé¿å…é¢å¤–çš„ç¼–ç é—®é¢˜
            raise Exception("åˆ›å»ºAPIå®¢æˆ·ç«¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥")

    def embed(self, texts: List[str], async_mode: bool = False, timeout: float = 5.0) -> List[List[float]]:
        """
        å°†æ–‡æœ¬åµŒå…¥ä¸ºå‘é‡
        
        Args:
            texts: è¦åµŒå…¥çš„æ–‡æœ¬åˆ—è¡¨
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼ˆä¸é˜»å¡ï¼‰
            timeout: å¼‚æ­¥æ¨¡å¼ä¸‹çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []

        # ç›´æ¥ä½¿ç”¨é»˜è®¤åµŒå…¥å‘é‡è€Œä¸å‘èµ·APIè¯·æ±‚
        embeddings = []
        for text in texts:
            # è·å–é»˜è®¤ç»´åº¦å‘é‡
            dim = self._get_model_dimension(self.model_name)
            # ç”Ÿæˆä¸€ä¸ªåŸºäºæ–‡æœ¬å“ˆå¸Œçš„ä¼ªéšæœºå‘é‡ï¼Œæ¯”å…¨é›¶å‘é‡æ›´æœ‰åŒºåˆ†åº¦
            try:
                text_bytes = text.encode('utf-8')
                hash_val = hashlib.md5(text_bytes).digest()
                # ä½¿ç”¨å“ˆå¸Œå€¼çš„æ¯ä¸ªå­—èŠ‚ç”Ÿæˆä¸€ä¸ª-1åˆ°1ä¹‹é—´çš„å€¼
                seed_values = [((b / 255.0) * 2 - 1) * 0.1 for b in hash_val]
                # æ‰©å±•seed_valuesåˆ°æ‰€éœ€ç»´åº¦
                embedding = []
                for i in range(dim):
                    # å¾ªç¯ä½¿ç”¨seed_valuesçš„å€¼ä½œä¸ºåŸºç¡€
                    base_val = seed_values[i % len(seed_values)]
                    # æ·»åŠ ä¸€äº›éšæœºæ€§ï¼Œä½†ä¿æŒä¸€å®šçš„ä¸€è‡´æ€§
                    adjusted_val = base_val + ((i * 0.01) % 0.1)
                    embedding.append(adjusted_val)
                
                # ç¼“å­˜ç»“æœ
                cache_key = hashlib.md5(text_bytes).hexdigest()
                self.cache[cache_key] = embedding
                print(f"âœ… å·²ç”Ÿæˆæœ¬åœ°ä¼ªåµŒå…¥å‘é‡ï¼Œç»´åº¦: {len(embedding)}")
                embeddings.append(embedding)
            except Exception as e:
                print(f"âš ï¸ ç”Ÿæˆä¼ªåµŒå…¥å‘é‡å¤±è´¥: {str(e)}")
                embeddings.append([0.0] * dim)
                
        return embeddings

    def _get_safe_model_name(self) -> str:
        """è·å–å®‰å…¨çš„æ¨¡å‹åç§°"""
        try:
            # ç¡®ä¿è¿”å›çš„æ˜¯çº¯ASCIIæ¨¡å‹åç§°
            safe_models = ["text-embedding-ada-002", "text-embedding-3-small", "text-embedding-3-large"]
            if str(self.model_name) in safe_models:
                return str(self.model_name)
            return "text-embedding-ada-002"  # é»˜è®¤ä½¿ç”¨æœ€ç¨³å®šçš„æ¨¡å‹
        except:
            return "text-embedding-ada-002"  # å‡ºé”™æ—¶è¿”å›é»˜è®¤æ¨¡å‹
        
    def _get_model_dimension(self, model_name: str) -> int:
        """è·å–æ¨¡å‹çš„å‘é‡ç»´åº¦"""
        dimension_map = {
            "text-embedding-ada-002": 1536,
            "text-embedding-3-small": 1536,
            "text-embedding-3-large": 3072
        }
        return dimension_map.get(model_name, 1536)  # é»˜è®¤è¿”å›1536ç»´

    def _async_embed(self, texts: List[str], timeout: float = 10.0) -> List[List[float]]:
        """å¼‚æ­¥æ–¹å¼å¤„ç†åµŒå…¥ï¼Œä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†å¤šä¸ªè¯·æ±‚"""
        import concurrent.futures
        
        if not texts:
            return []

        # åˆ›å»ºç»“æœåˆ—è¡¨
        dim = self._get_model_dimension()
        results = [[0.0] * dim for _ in range(len(texts))]
        
        # è¿›è¡Œåˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š8ä¸ªæ–‡æœ¬
        batch_size = 8
        batches = []
        
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i+batch_size]
            batches.append((i, batch_texts))
            
        # å®šä¹‰æ‰¹å¤„ç†å‡½æ•°
        def _process_batch(start_idx, batch):
            batch_results = self._embed_batch(batch, timeout)
            return start_idx, batch_results
            
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with concurrent.futures.ThreadPoolExecutor(max_workers=min(4, len(batches))) as executor:
            futures = [executor.submit(_process_batch, start_idx, batch) for start_idx, batch in batches]
            
            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(futures):
                try:
                    start_idx, batch_results = future.result()
                    for i, embedding in enumerate(batch_results):
                        if start_idx + i < len(results):
                            results[start_idx + i] = embedding
                except Exception as e:
                    safe_print(f"âŒ å¼‚æ­¥æ‰¹å¤„ç†å¤±è´¥: {str(e)}")
                    
        return results
    
    def get_cache_stats(self):
        """è¿”å›ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total = self.cache_hits + self.api_calls
        hit_rate = (self.cache_hits / total) * 100 if total > 0 else 0
        stats = {
            "cache_size": len(self.cache),
            "cache_hits": self.cache_hits,
            "api_calls": self.api_calls,
            "hit_rate_percent": hit_rate
        }
        print(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡ï¼šå‘½ä¸­ç‡ {hit_rate:.1f}%ï¼Œç¼“å­˜å¤§å° {len(self.cache)}ï¼Œå‘½ä¸­æ•° {self.cache_hits}ï¼ŒAPIè°ƒç”¨æ•° {self.api_calls}")
        return stats
        
    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        cache_size = len(self.cache)
        self.cache.clear()
        return f"å·²æ¸…é™¤ {cache_size} æ¡ç¼“å­˜åµŒå…¥"


class SiliconFlowEmbeddingModel(EmbeddingModel):
    """ç¡…åŸºæµåŠ¨APIçš„åµŒå…¥æ¨¡å‹å®ç°"""
    
    # æ¨¡å‹æ˜ å°„è¡¨
    _MODEL_DIMENSIONS = {
        "BAAI/bge-m3": 1024,
        "BAAI/bge-large-zh-v1.5": 1024,
        "BAAI/bge-large-en-v1.5": 1024,
        "BAAI/bge-small-zh-v1.5": 512,
        "BAAI/bge-small-en-v1.5": 512
    }

    def __init__(self, model_name: str, api_key: Optional[str] = None, 
                 api_url: str = "https://api.siliconflow.cn/v1/embeddings"):
        # å¤„ç†å­—å…¸æ ¼å¼çš„model_nameå‚æ•°
        if isinstance(model_name, dict) and 'value' in model_name:
            model_name = model_name['value']
            
        # å¤„ç†å­—å…¸æ ¼å¼çš„api_urlå‚æ•°
        if isinstance(api_url, dict) and 'value' in api_url:
            safe_print(f"ç¡…åŸºæµåŠ¨API URLæ˜¯å¯¹è±¡æ ¼å¼ï¼Œå€¼ä¸º: {api_url['value']}")
            api_url = api_url['value']
            
        self.model_name = str(model_name)
        self.api_key = api_key
        self.api_url = api_url
        self.api_calls = 0
        self.cache = {}
        self.cache_hits = 0
        
        # ç¡®ä¿api_urlæ˜¯ç»å¯¹URL
        if self.api_url and not self.api_url.startswith('http'):
            self.api_url = f"https://{self.api_url}"
            
        # æ¨¡å‹ç»´åº¦æ˜ å°„è¡¨
        self.model_dimensions = {
            "BAAI/bge-m3": 1024,
            "BAAI/bge-large-zh-v1.5": 1024,
            "BAAI/bge-large-en-v1.5": 1024,
            "BAAI/bge-small-zh-v1.5": 512,
            "BAAI/bge-small-en-v1.5": 512,
            "BAAI/bge-reranker-v2-m3": 1024,  # ä¸æ”¯æŒåµŒå…¥ï¼Œä½†æ·»åŠ ç»´åº¦é¿å…é”™è¯¯
            "Pro/BAAI/bge-m3": 1024,
            "Pro/BAAI/bge-reranker-v2-m3": 1024
        }
        
        # åˆ›å»ºä¼šè¯
        self.session = requests.Session()
        
        # ç¦ç”¨ä»£ç†ï¼Œé˜²æ­¢ä»£ç†é”™è¯¯
        self.session.trust_env = False
        
        # ä½¿ç”¨è‡ªå®šä¹‰User-Agenté¿å…æŸäº›é˜²ç«å¢™çš„æ‹¦æˆª
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 KouriChatRAG/1.0",
            "Content-Type": "application/json"
        })
        
        if self.api_key:
            self.session.headers.update({
                "Authorization": f"Bearer {self.api_key}"
            })
        
        # è¿æ¥æµ‹è¯•æ ‡å¿—
        self.connection_tested = False

    def _test_api_connection(self):
        """æµ‹è¯•APIè¿æ¥"""
        # è·³è¿‡APIè¿æ¥æµ‹è¯•ï¼Œç›´æ¥è¿”å›æˆåŠŸ
        logger.debug("è·³è¿‡APIè¿æ¥æµ‹è¯•ï¼Œç›´æ¥è¿”å›æˆåŠŸ")
        self.connection_tested = True
        return True

    def embed(self, texts: List[str], async_mode: bool = False, timeout: float = 10.0) -> List[List[float]]:
        """
        ä½¿ç”¨ç¡…åŸºæµåŠ¨APIå°†æ–‡æœ¬åµŒå…¥ä¸ºå‘é‡
        
        Args:
            texts: è¦åµŒå…¥çš„æ–‡æœ¬åˆ—è¡¨
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []
            
        # å¦‚æœæ˜¯å•ä¸ªæ–‡æœ¬å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(texts, str):
            texts = [texts]
            
        # è¿‡æ»¤ç©ºæ–‡æœ¬
        texts = [text for text in texts if text and isinstance(text, str)]
        if not texts:
            return []
            
        # è®¡æ•°APIè°ƒç”¨
        self.api_calls += 1
        
        # æ£€æŸ¥ç¼“å­˜
        if len(texts) == 1 and texts[0] in self.cache:
            self.cache_hits += 1
            return [self.cache[texts[0]]]
            
        # ä½¿ç”¨å¼‚æ­¥æ¨¡å¼å¤„ç†å¤šæ–‡æœ¬
        if async_mode and len(texts) > 1:
            return self._async_embed(texts, timeout)
            
        # å¸¸è§„å¤„ç†æ–¹å¼
        if len(texts) <= 16:  # å°æ‰¹é‡ç›´æ¥å¤„ç†
            return self._embed_batch(texts, timeout)
        else:  # å¤§æ‰¹é‡åˆ†æ‰¹å¤„ç†
            batch_size = 16
            result = []
            
            for i in range(0, len(texts), batch_size):
                batch = texts[i:i + batch_size]
                batch_result = self._embed_batch(batch, timeout)
                result.extend(batch_result)
                
            return result

    def _embed_batch(self, texts: List[str], timeout: float = 10.0) -> List[List[float]]:
        """å¤„ç†ä¸€æ‰¹æ–‡æœ¬çš„åµŒå…¥"""
        embeddings = []
        
        # æ£€æŸ¥API URLå’Œæ¨¡å‹åç§°
        if not self.api_url:
            safe_print("API URLä¸ºç©ºï¼Œæ— æ³•ç”ŸæˆåµŒå…¥")
            return [[0.0] * self._get_model_dimension()] * len(texts)
            
        # ç¼“å­˜å¤„ç†
        cached_indices = []
        uncached_texts = []
        uncached_indices = []
        
        # å°è¯•ä»ç¼“å­˜è·å–
        for i, text in enumerate(texts):
            if not text or not isinstance(text, str):
                embeddings.append([0.0] * self._get_model_dimension())
                continue
                
            # ç”Ÿæˆç¼“å­˜é”®
            try:
                cache_key = hashlib.md5(text.encode('utf-8')).hexdigest()
            except Exception:
                cache_key = hashlib.md5("default_text".encode('utf-8')).hexdigest()
                
            # æ£€æŸ¥ç¼“å­˜
            if cache_key in self.cache:
                self.cache_hits += 1
                cached_indices.append(i)
                embeddings.append(self.cache[cache_key])
                safe_print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­ç´¢å¼• {i}ï¼Œå½“å‰ç¼“å­˜å‘½ä¸­æ•°: {self.cache_hits}ï¼ŒAPIè°ƒç”¨æ•°: {self.api_calls}")
            else:
                uncached_texts.append(text.encode('utf-8').decode('utf-8'))  # ç¡®ä¿æ­£ç¡®ç¼–ç 
                uncached_indices.append(i)
                embeddings.append(None)  # å ä½ï¼Œç¨åå¡«å……
                
        # å¦‚æœæ‰€æœ‰æ–‡æœ¬éƒ½å·²ç¼“å­˜ï¼Œç›´æ¥è¿”å›
        if not uncached_texts:
            return embeddings
            
        # ä¸ºæœªç¼“å­˜çš„æ–‡æœ¬åˆ›å»ºåµŒå…¥
        try:
            # å‡†å¤‡è¯·æ±‚å‚æ•°
            payload = {
                "model": self.model_name,
                "input": uncached_texts,
                "encoding_format": "float"
            }
            
            # å‘é€APIè¯·æ±‚
            safe_print(f"è¯·æ±‚ç¡…åŸºæµåŠ¨åµŒå…¥APIï¼Œ{len(uncached_texts)}ä¸ªæ–‡æœ¬")
            
            # ä½¿ç”¨ä¼šè¯å‘é€è¯·æ±‚
            response = self.session.post(
                self.api_url,
                json=payload,
                timeout=timeout
            )
            
            self.api_calls += 1
            
            # å¤„ç†å“åº”
            if response.status_code == 200:
                result = response.json()
                
                if 'data' in result and len(result['data']) == len(uncached_texts):
                    # æˆåŠŸè·å–åµŒå…¥ï¼Œæ›´æ–°ç¼“å­˜å’Œç»“æœ
                    for i, (text, embedding_data) in enumerate(zip(uncached_texts, result['data'])):
                        if 'embedding' in embedding_data:
                            embedding = embedding_data['embedding']
                            
                            # ç¼“å­˜ç»“æœ
                            cache_key = hashlib.md5(text.encode('utf-8')).hexdigest()
                            self.cache[cache_key] = embedding
                            safe_print(f"ğŸ“¥ å·²ç¼“å­˜ç´¢å¼• {i} çš„åµŒå…¥å‘é‡ï¼Œå½“å‰ç¼“å­˜å¤§å°: {len(self.cache)}")
                            
                            # å¡«å……ç»“æœæ•°ç»„
                            original_idx = uncached_indices[i]
                            embeddings[original_idx] = embedding
                else:
                    # APIè¿”å›æ ¼å¼ä¸æ­£ç¡®
                    error_msg = f"APIè¿”å›æ ¼å¼é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                    safe_print(f"âš ï¸ {error_msg}")
                    
                    # ä½¿ç”¨é›¶å‘é‡å¡«å……
                    dim = self._get_model_dimension()
                    for idx in uncached_indices:
                        embeddings[idx] = [0.0] * dim
            else:
                # å¤„ç†é”™è¯¯çŠ¶æ€ç 
                error_msg = f"APIé”™è¯¯ï¼ŒçŠ¶æ€ç : {response.status_code}"
                safe_print(f"âš ï¸ {error_msg}")
                
                # å°è¯•è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
                try:
                    error_details = response.json().get('error', {})
                    if error_details:
                        safe_print(f"é”™è¯¯è¯¦æƒ…: {error_details}")
                except:
                    pass
                    
                # ä½¿ç”¨é›¶å‘é‡å¡«å……
                dim = self._get_model_dimension()
                for idx in uncached_indices:
                    embeddings[idx] = [0.0] * dim
                    
        except Exception as e:
            # å¤„ç†è¯·æ±‚å¼‚å¸¸
            error_msg = str(e)
            safe_print(f"âŒ åµŒå…¥è¯·æ±‚å¤±è´¥: {error_msg}")
            
            # ä½¿ç”¨é›¶å‘é‡å¡«å……
            dim = self._get_model_dimension()
            for idx in uncached_indices:
                embeddings[idx] = [0.0] * dim
                
        # ç¡®ä¿æ‰€æœ‰ä½ç½®éƒ½æœ‰åµŒå…¥å‘é‡
        for i, emb in enumerate(embeddings):
            if emb is None:
                embeddings[i] = [0.0] * self._get_model_dimension()
                
        return embeddings

    def _async_embed(self, texts: List[str], timeout: float = 10.0) -> List[List[float]]:
        """å¼‚æ­¥æ–¹å¼å¤„ç†åµŒå…¥ï¼Œä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†å¤šä¸ªè¯·æ±‚"""
        import concurrent.futures
        
        if not texts:
            return []

        # åˆ›å»ºç»“æœåˆ—è¡¨
        dim = self._get_model_dimension()
        results = [[0.0] * dim for _ in range(len(texts))]
        
        # è¿›è¡Œåˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š8ä¸ªæ–‡æœ¬
        batch_size = 8
        batches = []
        
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i+batch_size]
            batches.append((i, batch_texts))
            
        # å®šä¹‰æ‰¹å¤„ç†å‡½æ•°
        def _process_batch(start_idx, batch):
            batch_results = self._embed_batch(batch, timeout)
            return start_idx, batch_results
            
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with concurrent.futures.ThreadPoolExecutor(max_workers=min(4, len(batches))) as executor:
            futures = [executor.submit(_process_batch, start_idx, batch) for start_idx, batch in batches]
            
            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(futures):
                try:
                    start_idx, batch_results = future.result()
                    for i, embedding in enumerate(batch_results):
                        if start_idx + i < len(results):
                            results[start_idx + i] = embedding
                except Exception as e:
                    safe_print(f"âŒ å¼‚æ­¥æ‰¹å¤„ç†å¤±è´¥: {str(e)}")
                    
        return results
    
    def get_cache_stats(self):
        """è¿”å›ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total = self.cache_hits + self.api_calls
        hit_rate = (self.cache_hits / total) * 100 if total > 0 else 0
        stats = {
            "cache_size": len(self.cache),
            "cache_hits": self.cache_hits,
            "api_calls": self.api_calls,
            "hit_rate_percent": hit_rate
        }
        print(f"ğŸ“Š ç¡…åŸºæµåŠ¨ç¼“å­˜ç»Ÿè®¡ï¼šå‘½ä¸­ç‡ {hit_rate:.1f}%ï¼Œç¼“å­˜å¤§å° {len(self.cache)}ï¼Œå‘½ä¸­æ•° {self.cache_hits}ï¼ŒAPIè°ƒç”¨æ•° {self.api_calls}")
        return stats
        
    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        cache_size = len(self.cache)
        self.cache.clear()
        return f"å·²æ¸…é™¤ {cache_size} æ¡ç¼“å­˜åµŒå…¥"

    def update_model_dimensions(self, model_name: str, dimension: int):
        """æ·»åŠ æˆ–æ›´æ–°æ¨¡å‹ç»´åº¦æ˜ å°„"""
        if model_name and dimension > 0:
            self.model_dimensions[model_name] = dimension
            return True
        return False

    def _get_model_dimension(self) -> int:
        """è·å–æ¨¡å‹çš„å‘é‡ç»´åº¦"""
        return self.model_dimensions.get(self.model_name, 1024)  # é»˜è®¤è¿”å›1024ç»´


class HybridEmbeddingModel(EmbeddingModel):
    """
    æ··åˆåµŒå…¥æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨APIæ¨¡å‹ï¼Œå¦‚æœAPIæ¨¡å‹å¤±è´¥åˆ™ä½¿ç”¨æœ¬åœ°æ¨¡å‹ã€‚
    å…è®¸ç”¨æˆ·é€‰æ‹©æ˜¯å¦ä¸‹è½½æœ¬åœ°å¤‡ç”¨æ¨¡å‹ï¼Œå¹¶æ ¹æ®ç”¨æˆ·é€‰æ‹©å’Œä¸‹è½½ç»“æœè°ƒæ•´æ¨¡å‹ä½¿ç”¨ç­–ç•¥ã€‚
    
    å‚æ•°:
        api_model: APIåµŒå…¥æ¨¡å‹å®ä¾‹ï¼Œå¯ä»¥æ˜¯OnlineEmbeddingModelæˆ–SiliconFlowEmbeddingModel
        local_model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„
        local_model_enabled: æ˜¯å¦å¯ç”¨æœ¬åœ°æ¨¡å‹
    """
    def __init__(self, api_model: Union[OnlineEmbeddingModel, SiliconFlowEmbeddingModel], 
                 local_model_path: str = "paraphrase-multilingual-MiniLM-L12-v2", 
                 local_model_enabled: bool = False):
        # å®‰å…¨å¤„ç†æ¨¡å‹åç§°
        # local_model_pathåº”è¯¥æ˜¯huggingfaceæ¨¡å‹IDæˆ–æœ¬åœ°è·¯å¾„
        self.local_model_path = local_model_path
        self.api_model = api_model
        self.local_model_enabled = local_model_enabled
        self.local_model = None
        self.cache = {}
        self.cache_hits = 0
        self.api_calls = 0
        self.local_calls = 0
        self.cache_keys = []
        self.api_errors = 0
        
        # å°è¯•è¯†åˆ«æ¨¡å‹ç±»å‹
        self.is_siliconflow = isinstance(api_model, SiliconFlowEmbeddingModel)
        
        # å¦‚æœé€‰æ‹©äº†æœ¬åœ°æ¨¡å‹ï¼Œåˆ™åˆå§‹åŒ–
        if local_model_enabled:
            self._initialize_local_model()
        
        # è¾“å‡ºåˆå§‹åŒ–ä¿¡æ¯
        try:
            if self.is_siliconflow:
                print(f"ç¡…åŸºæµåŠ¨åµŒå…¥æ¨¡å‹å·²åˆå§‹åŒ–: {api_model.model_name}")
            else:
                print(f"APIåµŒå…¥æ¨¡å‹å·²åˆå§‹åŒ–: {api_model.model_name}")
        except:
            print("APIåµŒå…¥æ¨¡å‹å·²åˆå§‹åŒ– (æ— æ³•æ˜¾ç¤ºæ¨¡å‹åç§°)")
        
        # æ ¹æ®local_model_enabledå†³å®šæ˜¯å¦åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹
        if local_model_enabled:
            print("\næœ¬åœ°æ¨¡å‹å·²å¯ç”¨ï¼Œæ­£åœ¨åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹...")
            self._initialize_local_model()
        else:
            print("\næœ¬åœ°æ¨¡å‹æœªå¯ç”¨ï¼Œå°†ä»…ä½¿ç”¨APIæ¨¡å‹")
            self.local_model_failed = True
            
        print("\n" + "="*80)
        print(f"åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {'API + æœ¬åœ°å¤‡ç”¨' if self.local_model_enabled else 'API' }")
        print("="*80 + "\n")
    
    def _initialize_local_model(self):
        """åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹"""
        print(f"\nå¼€å§‹åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹: '{self.local_model_path}'")
        print("åˆå§‹åŒ–è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        try:
            # è®¾ç½®åˆå§‹åŒ–è¶…æ—¶å’Œæ¨¡å‹å¤§å°ä¼°è®¡
            import time
            import threading
            import sys
            
            start_time = time.time()
            init_started = False
            init_completed = False
            init_error = None
            
            # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºçº¿ç¨‹
            def show_progress():
                spinner = ['â£¾', 'â£½', 'â£»', 'â¢¿', 'â¡¿', 'â£Ÿ', 'â£¯', 'â£·']
                spinner_idx = 0
                elapsed_time = 0
                
                while not (init_completed or init_error):
                    if init_started:
                        # æ˜¾ç¤ºè¿›åº¦åŠ¨ç”»
                        elapsed_time = time.time() - start_time
                        sys.stdout.write(f"\råˆå§‹åŒ–ä¸­... {spinner[spinner_idx]} å·²ç”¨æ—¶: {elapsed_time:.1f}ç§’")
                        sys.stdout.flush()
                        spinner_idx = (spinner_idx + 1) % len(spinner)
                    time.sleep(0.1)
            
            # å¯åŠ¨è¿›åº¦æ˜¾ç¤ºçº¿ç¨‹
            progress_thread = threading.Thread(target=show_progress)
            progress_thread.daemon = True
            progress_thread.start()
            
            # åˆ›å»ºåˆå§‹åŒ–çº¿ç¨‹
            def init_model():
                nonlocal init_started, init_completed, init_error
                try:
                    init_started = True
                    # å°è¯•åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹
                    self.local_model = LocalEmbeddingModel(self.local_model_path)
                    init_completed = True
                except Exception as e:
                    init_error = e
            
            # å¯åŠ¨åˆå§‹åŒ–çº¿ç¨‹
            init_thread = threading.Thread(target=init_model)
            init_thread.start()
            
            # ç­‰å¾…åˆå§‹åŒ–å®Œæˆæˆ–è¶…æ—¶
            max_wait_time = 300  # æœ€å¤šç­‰å¾…5åˆ†é’Ÿ
            while init_thread.is_alive() and time.time() - start_time < max_wait_time:
                time.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡çŠ¶æ€
            
            # æ£€æŸ¥åˆå§‹åŒ–ç»“æœ
            if init_completed:
                init_time = time.time() - start_time
                sys.stdout.write("\r" + " " * 50 + "\r")  # æ¸…é™¤è¿›åº¦è¡Œ
                print(f"\nâœ… æœ¬åœ°æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ! ç”¨æ—¶: {init_time:.1f}ç§’")
                print(f"æ¨¡å‹å·²åŠ è½½åˆ°å†…å­˜ï¼Œå°†åœ¨APIè°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨")
                self.use_local_model = True
            elif init_error:
                sys.stdout.write("\r" + " " * 50 + "\r")  # æ¸…é™¤è¿›åº¦è¡Œ
                print(f"\nâŒ æœ¬åœ°æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(init_error)}")
                print("è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®")
                print("ç³»ç»Ÿå°†ä»…ä½¿ç”¨APIæ¨¡å‹")
                self.local_model_failed = True
            else:
                sys.stdout.write("\r" + " " * 50 + "\r")  # æ¸…é™¤è¿›åº¦è¡Œ
                print(f"\nâŒ æœ¬åœ°æ¨¡å‹åˆå§‹åŒ–è¶…æ—¶ï¼ˆè¶…è¿‡{max_wait_time/60:.1f}åˆ†é’Ÿï¼‰")
                print("è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„å’Œç³»ç»Ÿèµ„æº")
                print("ç³»ç»Ÿå°†ä»…ä½¿ç”¨APIæ¨¡å‹")
                self.local_model_failed = True
                
        except Exception as e:
            print(f"\nâŒ æœ¬åœ°æ¨¡å‹åˆå§‹åŒ–è¿‡ç¨‹å‡ºé”™: {str(e)}")
            print("è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„å’Œç³»ç»Ÿèµ„æº")
            print("ç³»ç»Ÿå°†ä»…ä½¿ç”¨APIæ¨¡å‹")
            self.local_model_failed = True

    def embed(self, texts: List[str], async_mode: bool = False, timeout: float = 5.0) -> List[List[float]]:
        """
        åµŒå…¥æ–‡æœ¬ï¼Œæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥æ¨¡å¼
        
        Args:
            texts: è¦åµŒå…¥çš„æ–‡æœ¬åˆ—è¡¨
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼ˆä¸é˜»å¡ï¼‰
            timeout: å¼‚æ­¥æ¨¡å¼ä¸‹çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []
        
        # å¼‚æ­¥æ¨¡å¼ä¼˜å…ˆä½¿ç”¨APIæ¨¡å‹çš„å¼‚æ­¥åµŒå…¥
        if async_mode:
            try:
                # ä½¿ç”¨å¼‚æ­¥æ¨¡å¼è°ƒç”¨APIæ¨¡å‹
                print(f"ä½¿ç”¨å¼‚æ­¥æ¨¡å¼åµŒå…¥ {len(texts)} ä¸ªæ–‡æœ¬...")
                return self.api_model.embed(texts, async_mode=True, timeout=timeout)
            except Exception as e:
                print(f"å¼‚æ­¥åµŒå…¥å¤±è´¥: {str(e)}")
                # è¿”å›é»˜è®¤é›¶å‘é‡
                default_dim = 1536
                return [[0.0] * default_dim for _ in range(len(texts))]
            
        # åŒæ­¥æ¨¡å¼
        results = []
        for text in texts:
            if not text or not isinstance(text, str):
                results.append([])
                continue
                
            # ä½¿ç”¨æ–‡æœ¬çš„MD5å“ˆå¸Œä½œä¸ºç¼“å­˜é”®ï¼Œå®‰å…¨å¤„ç†
            try:
                cache_key = hashlib.md5(text.encode('utf-8')).hexdigest()
            except Exception as e:
                print(f"âš ï¸ ç”Ÿæˆç¼“å­˜é”®æ—¶å‡ºé”™: {str(e)}")
                cache_key = hashlib.md5("default_text".encode('utf-8')).hexdigest()
            
            # æ£€æŸ¥ç¼“å­˜
            if cache_key in self.cache:
                try:
                    print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­: {text[:20]}...")
                except:
                    print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­ (æ— æ³•æ˜¾ç¤ºæ–‡æœ¬)")
                results.append(self.cache[cache_key])
                continue
                
            # ä¼˜å…ˆä½¿ç”¨APIæ¨¡å‹ (æœ€å¤š3æ¬¡å°è¯•ï¼ŒåŒ…æ‹¬ç¬¬ä¸€æ¬¡)
            api_success = False
            api_error = None
            
            for attempt in range(3):
                try:
                    if attempt > 0:
                        print(f"APIåµŒå…¥é‡è¯• ({attempt}/2)...")
                    embedding = self.api_model.embed([text])[0]
                    self.cache[cache_key] = embedding
                    results.append(embedding)
                    api_success = True
                    break
                except Exception as e:
                    api_error = e
                    print(f"âŒ APIåµŒå…¥{'' if attempt == 0 else 'é‡è¯•'}å¤±è´¥: {str(e)}")
                    # çŸ­æš‚ç­‰å¾…åé‡è¯•
                    if attempt < 2:  # åªåœ¨å‰ä¸¤æ¬¡å¤±è´¥åç­‰å¾…
                        import time
                        time.sleep(1)
            
            # å¦‚æœAPIè°ƒç”¨æˆåŠŸï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡æœ¬
            if api_success:
                continue
                
            # APIè°ƒç”¨å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            if self.local_model_failed:
                print(f"âš ï¸ APIåµŒå…¥å¤±è´¥ä¸”æœ¬åœ°æ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨é›¶å‘é‡")
                # ä½¿ç”¨é›¶å‘é‡ä»£æ›¿
                dim = 1024  # é»˜è®¤ç»´åº¦
                results.append([0.0] * dim)
                continue
            
            # å°è¯•ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            try:
                print(f"å°è¯•ä½¿ç”¨æœ¬åœ°å¤‡ç”¨æ¨¡å‹è¿›è¡ŒåµŒå…¥...")
                embedding = self.local_model.embed([text])[0]
                print(f"âœ… æœ¬åœ°æ¨¡å‹åµŒå…¥æˆåŠŸ")
                self.cache[cache_key] = embedding
                results.append(embedding)
            except Exception as local_error:
                print(f"âŒ æœ¬åœ°æ¨¡å‹åµŒå…¥ä¹Ÿå¤±è´¥: {str(local_error)}")
                # æ ‡è®°æœ¬åœ°æ¨¡å‹ä¸ºä¸å¯ç”¨
                self.local_model_failed = True
                print(f"âš ï¸ æœ¬åœ°æ¨¡å‹å·²è¢«æ ‡è®°ä¸ºä¸å¯ç”¨ï¼Œä»Šåå°†ä¸å†å°è¯•")
                # ä½¿ç”¨é›¶å‘é‡ä»£æ›¿
                dim = 1536  # é»˜è®¤ç»´åº¦
                results.append([0.0] * dim)
        
        return results
    
    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        cache_size = len(self.cache)
        self.cache.clear()
        return f"å·²æ¸…é™¤ {cache_size} æ¡ç¼“å­˜åµŒå…¥"


class ReRanker(ABC):
    @abstractmethod
    def rerank(self, query: str, documents: List[str]) -> List[float]:
        pass


class CrossEncoderReRanker(ReRanker):
    def __init__(self, model_path: str):
        self.model = CrossEncoder(model_path)

    def rerank(self, query: str, documents: List[str]) -> List[float]:
        pairs = [[query, doc] for doc in documents]
        return self.model.predict(pairs).tolist()


class OnlineCrossEncoderReRanker(ReRanker):
    def __init__(self, model_name: str, api_key: Optional[str] = None, base_url: Optional[str] = None):
        self.model_name = model_name
        self.client = OpenAI(api_key=api_key, base_url=base_url)

    def rerank(self, query: str, documents: List[str]) -> List[float]:
        scores = []
        for doc in documents:
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system",
                         "content": "æ‚¨æ˜¯ä¸€ä¸ªå¸®åŠ©è¯„ä¼°æ–‡æ¡£ä¸æŸ¥è¯¢ç›¸å…³æ€§çš„åŠ©æ‰‹ã€‚è¯·ä»…è¿”å›ä¸€ä¸ª0åˆ°1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡æœ¬ã€‚"},
                        {"role": "user", "content": f"æŸ¥è¯¢ï¼š{query}\næ–‡æ¡£ï¼š{doc}\nè¯·è¯„ä¼°è¯¥æ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§åˆ†æ•°ï¼ˆ0-1ï¼‰ï¼š"}
                    ]
                )
                content = response.choices[0].message.content.strip()
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ•°å€¼
                match = re.search(r"0?\.\d+|\d\.?\d*", content)
                if match:
                    score = float(match.group())
                    score = max(0.0, min(1.0, score))  # ç¡®ä¿åˆ†æ•°åœ¨0-1ä¹‹é—´
                else:
                    score = 0.0  # è§£æå¤±è´¥é»˜è®¤å€¼
            except Exception as e:
                score = 0.0  # å¼‚å¸¸å¤„ç†
            scores.append(score)
        return scores


class SiliconFlowReRanker(ReRanker):
    """
    ä½¿ç”¨ç¡…åŸºæµåŠ¨APIçš„é‡æ’å™¨ï¼Œé€šè¿‡å¤§æ¨¡å‹è¯„ä¼°æŸ¥è¯¢ä¸æ–‡æ¡£çš„ç›¸å…³æ€§ã€‚
    """
    def __init__(self, model_name: str, api_key: Optional[str] = None, 
                 api_url: str = "https://api.siliconflow.cn/v1/chat/completions"):
        self.model_name = model_name
        self.api_key = api_key
        self.api_url = api_url
        
    def rerank(self, query: str, documents: List[str]) -> List[float]:
        """
        é‡æ–°æ’åºæ–‡æ¡£åˆ—è¡¨ï¼Œæ ¹æ®ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§ã€‚
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: å€™é€‰æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            ç›¸å…³æ€§åˆ†æ•°åˆ—è¡¨ï¼Œåˆ†æ•°èŒƒå›´0-1
        """
        scores = []
        for doc in documents:
            try:
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "model": self.model_name,
                    "messages": [
                        {"role": "system", 
                         "content": "æ‚¨æ˜¯ä¸€ä¸ªå¸®åŠ©è¯„ä¼°æ–‡æ¡£ä¸æŸ¥è¯¢ç›¸å…³æ€§çš„åŠ©æ‰‹ã€‚è¯·ä»…è¿”å›ä¸€ä¸ª0åˆ°1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡æœ¬ã€‚"},
                        {"role": "user", 
                         "content": f"æŸ¥è¯¢ï¼š{query}\næ–‡æ¡£ï¼š{doc}\nè¯·è¯„ä¼°è¯¥æ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§åˆ†æ•°ï¼ˆ0-1ï¼‰ï¼š"}
                    ],
                    "temperature": 0.1,  # ä½æ¸©åº¦ä»¥è·å¾—ä¸€è‡´çš„è¯„åˆ†
                    "max_tokens": 10     # åªéœ€è¦ä¸€ä¸ªæ•°å­—
                }
                
                response = requests.post(
                    self.api_url,
                    json=payload,
                    headers=headers,
                    timeout=5,
                    proxies={}  # æ˜ç¡®ç¦ç”¨ä»£ç†
                )
                
                if response.status_code == 200:
                    response_data = response.json()
                    if 'choices' in response_data and len(response_data['choices']) > 0:
                        content = response_data['choices'][0].get('message', {}).get('content', '')
                        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ•°å€¼
                        match = re.search(r"0?\.\d+|\d\.?\d*", content)
                        if match:
                            score = float(match.group())
                            score = max(0.0, min(1.0, score))  # ç¡®ä¿åˆ†æ•°åœ¨0-1ä¹‹é—´
                            scores.append(score)
                            continue
                
                # å¦‚æœä¸Šé¢çš„å¤„ç†å¤±è´¥ï¼Œæ·»åŠ é»˜è®¤åˆ†æ•°
                scores.append(0.5)  # é»˜è®¤ä¸­ç­‰ç›¸å…³æ€§
                    
            except Exception as e:
                safe_print(f"é‡æ’åºè¿‡ç¨‹å‡ºé”™: {str(e)}")
                scores.append(0.5)  # å‘ç”Ÿé”™è¯¯æ—¶ä½¿ç”¨é»˜è®¤åˆ†æ•°
                
        return scores


class SiliconFlowNativeReRanker(ReRanker):
    """ä½¿ç”¨ç¡…åŸºæµåŠ¨åŸç”Ÿé‡æ’åºAPIçš„é‡æ’å™¨"""
    
    def __init__(self, model_name: str = "BAAI/bge-reranker-v2-m3", api_key: Optional[str] = None,
                 api_url: str = "https://api.siliconflow.cn/v1/rerank", 
                 top_n: int = None, return_documents: bool = False):
        # å¤„ç†å­—å…¸æ ¼å¼çš„model_nameå‚æ•°
        if isinstance(model_name, dict) and 'value' in model_name:
            model_name = model_name['value']
            
        # å¤„ç†å­—å…¸æ ¼å¼çš„api_urlå‚æ•°
        if isinstance(api_url, dict) and 'value' in api_url:
            safe_print(f"ç¡…åŸºæµåŠ¨é‡æ’åºAPI URLæ˜¯å¯¹è±¡æ ¼å¼ï¼Œå€¼ä¸º: {api_url['value']}")
            api_url = api_url['value']
            
        self.model_name = model_name
        self.api_key = api_key
        self.api_url = api_url
        self.top_n = top_n
        self.return_documents = return_documents
        
        # åˆå§‹åŒ–ä¼šè¯
        self.session = requests.Session()
        self.session.trust_env = False  # ç¦ç”¨ä»£ç†ï¼Œé˜²æ­¢ä»£ç†é”™è¯¯
        
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 KouriChatRAG/1.0",
            "Content-Type": "application/json"
        })
        
        if self.api_key:
            self.session.headers.update({
                "Authorization": f"Bearer {self.api_key}"
            })
    
    def rerank(self, query: str, documents: List[str]) -> List[float]:
        """
        ä½¿ç”¨ç¡…åŸºæµåŠ¨åŸç”Ÿé‡æ’åºAPIé‡æ–°æ’åºæ–‡æ¡£åˆ—è¡¨
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: å€™é€‰æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            ç›¸å…³æ€§åˆ†æ•°åˆ—è¡¨ï¼Œåˆ†æ•°èŒƒå›´0-1
        """
        if not documents:
            return []
            
        scores = [0.5] * len(documents)  # é»˜è®¤ä¸­ç­‰ç›¸å…³æ€§
        
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": self.model_name,
                "query": query,
                "documents": documents,
                "return_documents": self.return_documents
            }
            
            # å¦‚æœæŒ‡å®šäº†top_nï¼Œåˆ™æ·»åŠ åˆ°è¯·æ±‚ä¸­
            if self.top_n is not None:
                payload["top_n"] = min(self.top_n, len(documents))
            
            safe_print(f"å‘é€ç¡…åŸºæµåŠ¨é‡æ’åºè¯·æ±‚...")
            
            response = requests.post(
                self.api_url,
                json=payload,
                headers=headers,
                timeout=30,  # é‡æ’åºå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
                proxies={}  # æ˜ç¡®ç¦ç”¨ä»£ç†
            )
            
            if response.status_code == 200:
                response_data = response.json()
                
                if 'results' in response_data and len(response_data['results']) > 0:
                    # åˆ›å»ºä¸€ä¸ªæ˜ å°„ï¼Œå°†ç´¢å¼•æ˜ å°„åˆ°åˆ†æ•°
                    score_mapping = {}
                    
                    for result in response_data['results']:
                        if 'index' in result and 'relevance_score' in result:
                            idx = result['index']
                            if 0 <= idx < len(documents):
                                score_mapping[idx] = result['relevance_score']
                    
                    # æ›´æ–°åˆ†æ•°åˆ—è¡¨
                    for i in range(len(documents)):
                        if i in score_mapping:
                            scores[i] = score_mapping[i]
                    
                    safe_print(f"âœ… é‡æ’åºæˆåŠŸï¼Œé‡æ’åºäº† {len(score_mapping)} ä¸ªæ–‡æ¡£")
                    return scores
                else:
                    safe_print("âŒ é‡æ’åºå“åº”ç¼ºå°‘ç»“æœ")
            else:
                safe_print(f"âŒ é‡æ’åºè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                if response.text:
                    safe_print(f"å“åº”å†…å®¹: {response.text[:200]}...")
                    
        except Exception as e:
            safe_print(f"âŒ é‡æ’åºè¿‡ç¨‹å‡ºé”™: {str(e)}")
            
        return scores  # è¿”å›é»˜è®¤åˆ†æ•°


class RAG:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None or not kwargs.get('singleton', True):
            cls._instance = super(RAG, cls).__new__(cls)
        return cls._instance

    def __init__(self,
                 embedding_model: EmbeddingModel = None,
                 reranker: Optional[ReRanker] = None,
                 singleton: bool = True
                 ):
        if not hasattr(self, 'initialized'):
            self.embedding_model = embedding_model
            self.reranker = reranker
            self.index = None
            self.documents = []
            self.initialized = True
            self.data_path = os.path.join(os.getcwd(), "data", "rag_data.pkl")
            
            # å°è¯•åŠ è½½ç°æœ‰æ•°æ®
            try:
                if os.path.exists(self.data_path) and self.embedding_model:
                    print(f"æ£€æµ‹åˆ°RAGæ•°æ®æ–‡ä»¶ï¼Œå°è¯•åŠ è½½: {self.data_path}")
                    self.load()
            except Exception as e:
                print(f"åŠ è½½ç°æœ‰RAGæ•°æ®å¤±è´¥: {str(e)}")

    def save(self):
        """
        ä¿å­˜å½“å‰RAGç´¢å¼•å’Œæ–‡æ¡£åˆ°æ–‡ä»¶
        """
        try:
            import pickle
            import os
            import logging
            
            # è·å–logger
            logger = logging.getLogger('main')
            
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            os.makedirs(os.path.dirname(self.data_path), exist_ok=True)
            
            # å‡†å¤‡è¦ä¿å­˜çš„æ•°æ®ï¼ˆä¸ä¿å­˜indexï¼Œå› ä¸ºå®ƒå¯ä»¥ä»æ–‡æ¡£é‡å»ºï¼‰
            data_to_save = {
                "documents": self.documents,
                "embedding_model_info": str(self.embedding_model)
            }
            
            # ä¿å­˜æ•°æ®
            with open(self.data_path, 'wb') as f:
                pickle.dump(data_to_save, f)
                
            # åŒæ—¶ä¿å­˜ä¸ºJSONæ ¼å¼ï¼ˆä¾¿äºæŸ¥çœ‹å’Œç¼–è¾‘ï¼‰
            export_result = self.export_to_json()
                
            print(f"å·²ä¿å­˜RAGæ•°æ®ï¼Œæ–‡æ¡£æ•°é‡: {len(self.documents)}")
            logger.info(f"å·²ä¿å­˜RAGè®°å¿†æ•°æ®ï¼Œæ–‡æ¡£æ•°é‡: {len(self.documents)}")
            
            if export_result:
                logger.info("æˆåŠŸå°†RAGè®°å¿†å¯¼å‡ºä¸ºJSONæ ¼å¼")
            
            return True
        except Exception as e:
            print(f"ä¿å­˜RAGæ•°æ®å¤±è´¥: {str(e)}")
            logging.getLogger('main').error(f"ä¿å­˜RAGæ•°æ®å¤±è´¥: {str(e)}")
            return False
    
    def export_to_json(self):
        """
        å°†RAGæ–‡æ¡£å¯¼å‡ºä¸ºJSONæ ¼å¼
        å°†å¯¹è¯æŒ‰ç…§æ–°æ ¼å¼ç»“æ„ä¿å­˜
        """
        try:
            import json
            import os
            import re
            import logging
            from datetime import datetime
            
            # è·å–logger
            logger = logging.getLogger('main')
            
            # ç¡®å®šJSONæ–‡ä»¶è·¯å¾„
            json_path = os.path.join(os.getcwd(), "data", "memory", "rag-memory.json")
            
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            os.makedirs(os.path.dirname(json_path), exist_ok=True)
            
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨ç°æœ‰çš„è®°å¿†æ–‡ä»¶
            existing_conversations = {}
            if os.path.exists(json_path):
                try:
                    logger.info(f"å‘ç°ç°æœ‰è®°å¿†æ–‡ä»¶ï¼Œå°è¯•è¯»å–: {json_path}")
                    with open(json_path, 'r', encoding='utf-8') as f:
                        existing_conversations = json.load(f)
                    logger.info(f"æˆåŠŸè¯»å–ç°æœ‰è®°å¿†ï¼ŒåŒ…å« {len(existing_conversations)} ä¸ªå¯¹è¯")
                except Exception as e:
                    logger.warning(f"è¯»å–ç°æœ‰è®°å¿†æ–‡ä»¶å¤±è´¥: {str(e)}")
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¯¹è¯æ¨¡å¼
            user_pattern = re.compile(r'^\[(.*?)\]å¯¹æ–¹\(ID:(.*?)\): (.*)$')
            ai_pattern = re.compile(r'^\[(.*?)\] ä½ : (.*)$')
            
            # æ•´ç†å¯¹è¯æ•°æ®
            conversation_index = len(existing_conversations)
            
            # æ”¶é›†æ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯
            user_messages = []
            for doc in self.documents:
                user_match = user_pattern.match(doc)
                if user_match:
                    timestamp, user_id, message = user_match.groups()
                    user_messages.append({
                        "doc": doc,
                        "timestamp": timestamp,
                        "user_id": user_id.strip(),
                        "message": message.strip()
                    })
            
            # åŒ¹é…AIå›å¤
            matched_conversations = []
            for user_msg in user_messages:
                # æ‰¾åˆ°åŒ¹é…çš„AIå›å¤
                matched = False
                for doc in self.documents:
                    ai_match = ai_pattern.match(doc)
                    if ai_match and user_msg["timestamp"].split()[0] in doc:  # åŒ¹é…æ—¥æœŸ
                        ai_timestamp, ai_response = ai_match.groups()
                        
                        # ä»configæˆ–ç¯å¢ƒå˜é‡è·å–å½“å‰è§’è‰²å
                        try:
                            from src.config import config
                            avatar_dir = config.behavior.context.avatar_dir
                            # æå–æœ€åä¸€ä¸ªç›®å½•ä½œä¸ºè§’è‰²å
                            avatar_name = os.path.basename(avatar_dir)
                        except:
                            avatar_name = "AIåŠ©æ‰‹"
                        
                        # ç¡®å®šæ˜¯å¦ä¸ºä¸»åŠ¨æ¶ˆæ¯ (ç®€å•åˆ¤æ–­ï¼šå¦‚æœæ¶ˆæ¯ä¸­åŒ…å«"ä¸»äºº"æˆ–ç±»ä¼¼è¯ï¼Œå¯èƒ½æ˜¯ä¸»åŠ¨æ¶ˆæ¯)
                        is_initiative = "ä¸»äºº" in user_msg["message"] or "æ‚¨å¥½" in user_msg["message"]
                        
                        # å°è¯•è·å–æƒ…ç»ª
                        emotion = "None"
                        try:
                            # å¯¼å…¥æƒ…æ„Ÿåˆ†ææ¨¡å—
                            from src.handlers.emotion import SentimentResourceLoader, SentimentAnalyzer
                            # åˆ›å»ºåˆ†æå™¨
                            resource_loader = SentimentResourceLoader()
                            analyzer = SentimentAnalyzer(resource_loader)
                            # åˆ†ææƒ…æ„Ÿ
                            sentiment_result = analyzer.analyze(ai_response)
                            emotion = sentiment_result.get('sentiment_type', 'None').lower()
                        except Exception as e:
                            print(f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {str(e)}")
                        
                        # å¡«å……å¯¹è¯æ•°æ®ç»“æ„
                        conversation_key = f"conversation{conversation_index}"
                        conversation_data = [{
                            "bot_time": ai_timestamp.strip(),
                            "sender_id": user_msg["user_id"],
                            "sender_text": user_msg["message"],
                            "receiver_id": avatar_name,
                            "receiver_text": ai_response.strip(),
                            "emotion": emotion,
                            "is_initiative": is_initiative  # ç¡®ä¿è¿™é‡Œæ²¡æœ‰ç©ºæ ¼
                        }]
                        matched_conversations.append(conversation_data)
                        conversation_index += 1
                        matched = True
                        break
            
            # ä¿å­˜ä¸ºJSON - åˆå¹¶æ–°å¯¹è¯å’Œç°æœ‰å¯¹è¯
            conversations = {**existing_conversations}
            
            # æ£€æŸ¥å¹¶ä¿®å¤ç°æœ‰è®°å¿†ä¸­çš„å­—æ®µåç§°é—®é¢˜
            modified = False
            for conv_key, conv_data in conversations.items():
                for entry in conv_data:
                    if "is_ initiative" in entry:
                        # è·å–logger
                        logger = logging.getLogger('main')
                        logger.warning(f"æ£€æµ‹åˆ°å­—æ®µå‘½åé—®é¢˜ï¼Œä¿®å¤'is_ initiative'ä¸º'is_initiative'")
                        entry["is_initiative"] = entry.pop("is_ initiative")
                        modified = True
            
            # å¦‚æœä¿®å¤äº†å­—æ®µï¼Œè®°å½•æ—¥å¿—
            if modified:
                logger.info("ä¿®å¤äº†å­—æ®µå‘½åé—®é¢˜")
                
            # è·å–æ–°çš„å¯¹è¯ç´¢å¼•èµ·ç‚¹
            next_index = len(existing_conversations)
            
            # éå†matched_conversationsï¼Œæ·»åŠ åˆ°conversations
            for i, conv in enumerate(matched_conversations):
                conversation_key = f"conversation{next_index + i}"
                conversations[conversation_key] = conv
            
            # ä¿å­˜ä¸ºJSON
            try:
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(json_path), exist_ok=True)
                
                # æ‰“å¼€æ–‡ä»¶å¹¶å†™å…¥
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(conversations, f, ensure_ascii=False, indent=2)
                
                # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸå†™å…¥
                file_size = os.path.getsize(json_path)
                
                logger.info(f"å·²å¯¼å‡ºRAGè®°å¿†åˆ°JSON: {json_path}, å…± {len(conversations)} æ¡å¯¹è¯ï¼Œæ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
                print(f"å·²å¯¼å‡ºRAGè®°å¿†åˆ°JSON: {json_path}, å…± {len(conversations)} æ¡å¯¹è¯ï¼Œæ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
                return True
            except Exception as file_err:
                logger.error(f"å†™å…¥JSONæ–‡ä»¶å¤±è´¥: {str(file_err)}")
                print(f"å†™å…¥JSONæ–‡ä»¶å¤±è´¥: {str(file_err)}")
                return False
        except Exception as e:
            print(f"å¯¼å‡ºRAGè®°å¿†åˆ°JSONå¤±è´¥: {str(e)}")
            logging.getLogger('main').error(f"å¯¼å‡ºRAGè®°å¿†åˆ°JSONå¤±è´¥: {str(e)}")
            traceback.print_exc()
            return False
            
    def import_from_json(self, json_path=None):
        """
        ä»JSONæ–‡ä»¶å¯¼å…¥è®°å¿†
        
        Args:
            json_path: JSONæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        """
        try:
            import json
            import os
            import logging
            
            # è·å–logger
            logger = logging.getLogger('main')
            
            # ç¡®å®šJSONæ–‡ä»¶è·¯å¾„
            if not json_path:
                json_path = os.path.join(os.getcwd(), "data", "memory", "rag-memory.json")
                
            if not os.path.exists(json_path):
                print(f"JSONè®°å¿†æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
                return False
                
            # åŠ è½½JSONæ•°æ®
            with open(json_path, 'r', encoding='utf-8') as f:
                conversations = json.load(f)
            
            # æ£€æŸ¥å¹¶ä¿®å¤å­—æ®µåé—®é¢˜
            modified = False
            for conv_key, conv_data in conversations.items():
                for entry in conv_data:
                    if "is_ initiative" in entry:
                        entry["is_initiative"] = entry.pop("is_ initiative")
                        modified = True
                        logger.info(f"ä¿®å¤äº†å­—æ®µå‘½åé—®é¢˜: 'is_ initiative' -> 'is_initiative'")
            
            # å¦‚æœä¿®æ”¹äº†ï¼Œä¿å­˜å›æ–‡ä»¶
            if modified:
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(conversations, f, ensure_ascii=False, indent=2)
                logger.info(f"ä¿å­˜äº†ä¿®å¤åçš„JSONæ–‡ä»¶")
                
            # æ¸…ç©ºç°æœ‰æ–‡æ¡£
            old_count = len(self.documents)
            self.documents = []
            if self.index:
                self.index.reset()
                
            # æ·»åŠ è®°å¿†
            new_docs = []
            
            # å¤„ç†æ–°æ ¼å¼çš„å¯¹è¯æ•°æ®
            for conv_key, conv_data in conversations.items():
                if not isinstance(conv_data, list) or not conv_data:
                    continue
                    
                for entry in conv_data:
                    # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨
                    if not all(k in entry for k in ["sender_id", "sender_text", "receiver_id", "receiver_text"]):
                        continue
                    
                    # æ£€æŸ¥æ—¶é—´å­—æ®µ (å…¼å®¹æ—§ç‰ˆæœ¬)
                    if "bot_time" in entry:
                        timestamp = entry["bot_time"]
                    elif "receiver_time" in entry:
                        timestamp = entry["receiver_time"]
                    else:
                        # å¦‚æœæ²¡æœ‰æ—¶é—´å­—æ®µï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                        from datetime import datetime
                        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
                    
                    # æ ¼å¼åŒ–ç”¨æˆ·æ¶ˆæ¯
                    sender_id = entry["sender_id"]
                    sender_text = entry["sender_text"]
                    
                    user_msg = f"[{timestamp}]å¯¹æ–¹(ID:{sender_id}): {sender_text}"
                    new_docs.append(user_msg)
                    
                    # æ ¼å¼åŒ–AIå›å¤
                    receiver_text = entry["receiver_text"]
                    ai_msg = f"[{timestamp}] ä½ : {receiver_text}"
                    new_docs.append(ai_msg)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡æ¡£
            if not new_docs:
                print("JSONæ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆè®°å¿†")
                return False
                
            # ç”ŸæˆåµŒå…¥å¹¶æ·»åŠ åˆ°ç´¢å¼•
            print(f"ä»JSONå¯¼å…¥ {len(new_docs)} æ¡è®°å¿†...")
            embeddings = self.embedding_model.embed(new_docs)
            
            # åˆå§‹åŒ–ç´¢å¼•
            if not self.index:
                embedding_dim = len(embeddings[0])
                self.index = faiss.IndexFlatL2(embedding_dim)
                
            # æ·»åŠ åˆ°ç´¢å¼•
            self.index.add(np.array(embeddings).astype('float32'))
            self.documents.extend(new_docs)
            
            print(f"æˆåŠŸä»JSONå¯¼å…¥è®°å¿†ï¼ŒåŸå§‹æ–‡æ¡£æ•°: {old_count}, å½“å‰æ–‡æ¡£æ•°: {len(self.documents)}")
            return True
        except Exception as e:
            print(f"ä»JSONå¯¼å…¥è®°å¿†å¤±è´¥: {str(e)}")
            traceback.print_exc()
            return False
            
    def load(self):
        """
        ä»æ–‡ä»¶åŠ è½½RAGç´¢å¼•å’Œæ–‡æ¡£
        """
        try:
            import pickle
            import os
            
            if not os.path.exists(self.data_path):
                print(f"RAGæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.data_path}")
                return False
                
            # åŠ è½½æ•°æ®
            with open(self.data_path, 'rb') as f:
                data = pickle.load(f)
                
            # æ¢å¤æ–‡æ¡£
            if "documents" in data and isinstance(data["documents"], list):
                self.documents = data["documents"]
                print(f"å·²åŠ è½½ {len(self.documents)} ä¸ªæ–‡æ¡£")
                
                # å¦‚æœæ–‡æ¡£å­˜åœ¨ï¼Œé‡å»ºç´¢å¼•
                if self.documents and self.embedding_model:
                    print("é‡å»ºç´¢å¼•...")
                    embeddings = self.embedding_model.embed(self.documents)
                    embedding_dim = len(embeddings[0])
                    self.index = faiss.IndexFlatL2(embedding_dim)
                    self.index.add(np.array(embeddings).astype('float32'))
                    print(f"ç´¢å¼•é‡å»ºå®Œæˆï¼Œæ–‡æ¡£æ•°é‡: {len(self.documents)}")
                    
            return True
        except Exception as e:
            print(f"åŠ è½½RAGæ•°æ®å¤±è´¥: {str(e)}")
            return False

    def initialize_index(self, dim: int = 1024):
        """æ˜¾å¼åˆå§‹åŒ–ç´¢å¼•ï¼Œé˜²æ­¢ç©ºæŒ‡é’ˆå¼‚å¸¸"""
        if self.index is None:
            self.index = faiss.IndexFlatL2(dim)
            print(f"å·²åˆå§‹åŒ–FAISSç´¢å¼•ï¼Œç»´åº¦: {dim}")

    def add_documents(self, documents=None, texts: List[str] = None):
        """
        æ·»åŠ æ–‡æ¡£åˆ°RAGç³»ç»Ÿ
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æˆ–å¯¹è±¡åˆ—è¡¨
            texts: æ–‡æœ¬åˆ—è¡¨ï¼Œå°†ç›´æ¥æ·»åŠ ä¸ºæ–‡æ¡£
            
        å¦‚æœåŒæ—¶æä¾›documentså’Œtextsï¼Œä¸¤è€…éƒ½ä¼šè¢«æ·»åŠ 
        """
        import logging
        logger = logging.getLogger('main')
        
        if not documents and not texts:
            logger.warning("æ²¡æœ‰æä¾›æ–‡æ¡£")
            return
        
        all_texts = []
        
        # å¤„ç†documentså‚æ•°
        if documents:
            logger.debug(f"æ¥æ”¶åˆ°documentså‚æ•°ï¼Œç±»å‹: {type(documents)}")
            logger.debug(f"åˆ—è¡¨åŒ…å« {len(documents)} ä¸ªé¡¹ç›®")
            if len(documents) > 0:
                logger.debug(f"ç¤ºä¾‹é¡¹ç›®1: {type(documents[0])}, {str(documents[0])[:100]}...")
            
            # å°è¯•æå–æ–‡æœ¬
            for doc in documents:
                if isinstance(doc, str):
                    # ç›´æ¥æ·»åŠ å­—ç¬¦ä¸²æ–‡æ¡£
                    all_texts.append(doc)
                elif isinstance(doc, tuple) and len(doc) >= 2:
                    # å¤„ç†(key, value)æ ¼å¼
                    logger.debug(f"å¤„ç†é”®å€¼å¯¹ - é”®ç±»å‹: {type(doc[0])}, å€¼ç±»å‹: {type(doc[1])}")
                    
                    # å¦‚æœéƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œåˆå¹¶ä¸ºä¸€ä¸ªæ–‡æ¡£
                    if isinstance(doc[0], str) and isinstance(doc[1], str):
                        key_str = str(doc[0])
                        value_str = str(doc[1])
                        combined_text = f"{key_str}: {value_str}"
                        logger.debug(f"åˆå¹¶é”®å€¼å¯¹ä¸ºå•ä¸€æ–‡æ¡£: {combined_text[:50]}...")
                        all_texts.append(combined_text)
                    elif isinstance(doc[1], str):
                        all_texts.append(doc[1])
                    elif isinstance(doc[0], str):
                        all_texts.append(doc[0])
                elif isinstance(doc, dict):
                    # ä¼˜å…ˆé€‰æ‹©æ›´å¸¸è§çš„å­—æ®µå
                    for field in ['text', 'content', 'body', 'message', 'value']:
                        if field in doc and isinstance(doc[field], str):
                            all_texts.append(doc[field])
                            break
                    else:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆå­—æ®µï¼Œå°è¯•ä½¿ç”¨å­—ç¬¦ä¸²è¡¨ç¤º
                        all_texts.append(str(doc))
                else:
                    # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    try:
                        all_texts.append(str(doc))
                    except:
                        logger.warning(f"è·³è¿‡æ— æ³•è½¬æ¢ä¸ºæ–‡æœ¬çš„æ–‡æ¡£: {type(doc)}")
        
        # å¤„ç†textså‚æ•°
        if texts:
            for text in texts:
                if isinstance(text, str):
                    all_texts.append(text)
        
        # é¢„å¤„ç†è¿‡æ»¤æ–‡æœ¬å†…å®¹
        filtered_texts = []
        for text in all_texts:
            if not text or not isinstance(text, str):
                continue
                
            # æ–‡æœ¬é•¿åº¦è¿‡æ»¤
            if len(text.strip()) < 5:  # è¿‡æ»¤æ‰è¿‡çŸ­çš„æ–‡æœ¬
                logger.debug(f"è·³è¿‡è¿‡çŸ­æ–‡æœ¬: {text}")
                continue
                
            # å†…å®¹è´¨é‡è¿‡æ»¤
            if self._is_low_quality_text(text):
                logger.debug(f"è·³è¿‡ä½è´¨é‡æ–‡æœ¬: {text[:50]}...")
                continue
                
            # åº”ç”¨æ–‡æœ¬æ¸…ç†ï¼ˆå¦‚æœèƒ½å¯¼å…¥ç›¸å…³å‡½æ•°ï¼‰
            try:
                from src.memories.memory_utils import clean_dialog_memory
                # å¯¹äºåŒ…å«å†’å·çš„æ–‡æœ¬ï¼Œå°è¯•ä½œä¸ºå¯¹è¯æ¸…ç†
                if ': ' in text or 'ï¼š' in text:
                    parts = text.split(':', 1) if ': ' in text else text.split('ï¼š', 1)
                    if len(parts) == 2:
                        _, cleaned_text = clean_dialog_memory(parts[0], parts[1])
                        if cleaned_text.strip():
                            text = cleaned_text
                
                # å¦‚æœæ¸…ç†åæ–‡æœ¬ä¸ºç©ºï¼Œåˆ™è·³è¿‡
                if not text.strip():
                    logger.debug("æ¸…ç†åæ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡")
                    continue
            except ImportError:
                # å¦‚æœæ— æ³•å¯¼å…¥æ¸…ç†å‡½æ•°ï¼Œè·³è¿‡æ¸…ç†æ­¥éª¤
                pass
                
            filtered_texts.append(text)
            
        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰æ–‡æœ¬ï¼Œç›´æ¥è¿”å›
        if not filtered_texts:
            logger.warning("è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆæ–‡æœ¬ï¼Œè·³è¿‡æ·»åŠ æ–‡æ¡£")
            return
        
        # å»é™¤å¯èƒ½çš„é‡å¤æ–‡æ¡£
        truly_new_texts = []
        existing_docs_set = set(self.documents)
        duplicate_count = 0
        
        for text in filtered_texts:
            if text in existing_docs_set:
                logger.debug(f"è·³è¿‡é‡å¤æ–‡æ¡£: {text[:50]}...")
                duplicate_count += 1
            else:
                truly_new_texts.append(text)
                existing_docs_set.add(text)
        
        if duplicate_count > 0:
            logger.info(f"è·³è¿‡ {duplicate_count} ä¸ªé‡å¤æ–‡æ¡£")
        
        if not truly_new_texts:
            return
        
        # ç”ŸæˆåµŒå…¥å‘é‡
        print("å¼€å§‹ç”Ÿæˆæ–‡æ¡£åµŒå…¥...")
        embeddings = self.embedding_model.embed(truly_new_texts)
        
        # ç¡®ä¿åµŒå…¥ç»´åº¦ä¸ç´¢å¼•ç»´åº¦åŒ¹é…
        if not embeddings or not isinstance(embeddings[0], list):
            print("âš ï¸ åµŒå…¥ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡æ·»åŠ æ–‡æ¡£")
            return
        
        # æ£€æŸ¥ç»´åº¦ä¸€è‡´æ€§
        print(f"åµŒå…¥ç»´åº¦: {np.array(embeddings).shape}")
        
        # åˆå§‹åŒ–ç´¢å¼•ï¼ˆå¦‚æœå°šæœªåˆå§‹åŒ–ï¼‰
        if not self.index:
            embedding_dim = len(embeddings[0])
            print(f"åˆå§‹åŒ–FAISSç´¢å¼•ï¼Œç»´åº¦: {embedding_dim}")
            self.index = faiss.IndexFlatL2(embedding_dim)
        
        # æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•
        self.index.add(np.array(embeddings).astype('float32'))
        self.documents.extend(truly_new_texts)
        
        print(f"ç´¢å¼•æ›´æ–°å®Œæˆï¼Œå½“å‰ç´¢å¼•åŒ…å« {len(self.documents)} ä¸ªæ–‡æ¡£")
        
        # ä¿å­˜RAGæ•°æ®åˆ°æ–‡ä»¶
        self.save()
        
    def _is_low_quality_text(self, text):
        """
        åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºä½è´¨é‡
        
        Args:
            text: å¾…åˆ¤æ–­æ–‡æœ¬
            
        Returns:
            bool: æ˜¯å¦ä¸ºä½è´¨é‡æ–‡æœ¬
        """
        import re
        
        # è½¬æ¢ä¸ºå°å†™ä¾¿äºåŒ¹é…
        lower_text = text.lower()
        
        # è¿‡æ»¤æ˜æ˜¾çš„ç³»ç»Ÿ/æŒ‡ä»¤æç¤º
        system_patterns = [
            r"è¯·æ³¨æ„[:ï¼š]", 
            r"å½“ä»»åŠ¡å®Œæˆæ—¶", 
            r"è¯·è®°ä½ä½ æ˜¯", 
            r"è¯·æ‰®æ¼”", 
            r"ä½ çš„å›å¤åº”è¯¥",
            r"ä½ ç°åœ¨æ˜¯ä¸€ä¸ª",
            r"ä½ ç°åœ¨åº”è¯¥æ‰®æ¼”",
            r"ä½ æ˜¯ä¸€ä¸ªAI",
            r"æˆ‘æ˜¯ä½ çš„ä¸»äºº",
            r"è¯·ä½ è®°ä½",
            r"è¯·ä¿æŒç®€æ´",
            r"è¯·å›å¤å¾—",
            r"æˆ‘å¸Œæœ›ä½ çš„å›å¤",
            r"åœ¨æ­¤æ¶ˆæ¯ä¹‹å",
            r"æˆ‘æƒ³è¦ä½ "
        ]
        
        for pattern in system_patterns:
            if re.search(pattern, lower_text):
                return True
                
        # è¿‡æ»¤é‡å¤æ¨¡å¼
        if self._has_excessive_repetition(text):
            return True
            
        # è¿‡æ»¤æ— æ„ä¹‰å­—ç¬¦ä¸²
        noise_patterns = [
            r"\[MASK\]", r"\[CLS\]", r"\[SEP\]", r"\[PAD\]", r"\[UNK\]",
            r"<s>", r"</s>", r"<p>", r"</p>", r"<div>", r"</div>",
            r"^[a-f0-9]{32,}$",  # MD5ç­‰å“ˆå¸Œå€¼
            r"^[a-zA-Z0-9+/]{40,}={0,2}$"  # Base64ç¼–ç 
        ]
        
        for pattern in noise_patterns:
            if re.search(pattern, text):
                return True
                
        # è¿‡æ»¤åŒ…å«å¤§é‡ç‰¹æ®Šç¬¦å·çš„æ–‡æœ¬
        special_chars = re.findall(r'[^\w\s\u4e00-\u9fffï¼Œã€‚ï¼Ÿï¼ï¼šï¼›""''ã€ã€‘ã€Œã€ã€ã€ï¼ˆï¼‰ã€]', text)
        if len(special_chars) / len(text) > 0.3:  # ç‰¹æ®Šå­—ç¬¦æ¯”ä¾‹è¿‡é«˜
            return True
            
        return False
        
    def _has_excessive_repetition(self, text):
        """
        æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦æœ‰è¿‡åº¦é‡å¤
        
        Args:
            text: å¾…æ£€æµ‹æ–‡æœ¬
            
        Returns:
            bool: æ˜¯å¦å­˜åœ¨è¿‡åº¦é‡å¤
        """
        import re
        
        # æ£€æŸ¥é‡å¤å•è¯
        words = re.findall(r'\b\w+\b', text.lower())
        if len(words) > 5:
            unique_words = set(words)
            if len(unique_words) / len(words) < 0.3:  # å¦‚æœä¸åŒå•è¯æ¯”ä¾‹è¿‡ä½
                return True
        
        # æ£€æŸ¥é‡å¤æ®µè½
        paragraphs = [p for p in text.split('\n') if p.strip()]
        if len(paragraphs) > 3:
            unique_paragraphs = set(paragraphs)
            if len(unique_paragraphs) / len(paragraphs) < 0.5:  # å¦‚æœä¸åŒæ®µè½æ¯”ä¾‹è¿‡ä½
                return True
                
        # æ£€æŸ¥é‡å¤æ¨¡å¼
        for length in range(3, min(10, len(text) // 2)):  # æ£€æŸ¥3-10ä¸ªå­—ç¬¦çš„é‡å¤
            for i in range(len(text) - length * 2):
                pattern = text[i:i+length]
                if pattern.strip() and text.count(pattern) > 3:  # åŒä¸€æ¨¡å¼é‡å¤è¶…è¿‡3æ¬¡
                    return True
                    
        return False

    def query(self, query: str, top_k: int = 5, rerank: bool = False, async_mode: bool = False, timeout: float = 5.0) -> List[str]:
        """
        æŸ¥è¯¢ç›¸å…³æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›çš„æœ€å¤§ç»“æœæ•°
            rerank: æ˜¯å¦å¯¹ç»“æœé‡æ’åº
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼ˆä¸é˜»å¡ï¼‰
            timeout: å¼‚æ­¥æ¨¡å¼ä¸‹çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        if not self.documents:
            return []
        
        # æ£€æŸ¥JSONè®°å¿†æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨ï¼Œå¯èƒ½éœ€è¦å…ˆå¯¼å…¥æœ€æ–°è®°å¿†
        try:
            import os
            import json
            
            json_path = os.path.join(os.getcwd(), "data", "memory", "rag-memory.json")
            if os.path.exists(json_path):
                # å°è¯•ä»JSONè·å–æœ€æ–°è®°å¿†
                self.import_from_json(json_path)
        except Exception as e:
            print(f"å°è¯•å¯¼å…¥æœ€æ–°JSONè®°å¿†å¤±è´¥: {str(e)}")
        
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        try:
            print(f"æ­£åœ¨ä¸ºæŸ¥è¯¢ç”ŸæˆåµŒå…¥å‘é‡: {query[:50]}...")
            query_embedding = self.embedding_model.embed([query], async_mode=async_mode, timeout=timeout)[0]
            
            # æ£€æŸ¥å‘é‡æ˜¯å¦ä¸ºç©º
            if not query_embedding:
                print("âš ï¸ æŸ¥è¯¢åµŒå…¥ç”Ÿæˆå¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ")
                return []
            
            # ç¡®ä¿æŸ¥è¯¢å‘é‡æ ¼å¼æ­£ç¡®
            if not isinstance(query_embedding, list):
                print("âš ï¸ æŸ¥è¯¢å‘é‡æ ¼å¼é”™è¯¯ï¼Œè¿”å›ç©ºç»“æœ")
                return []
                
            # æœç´¢ç›¸ä¼¼æ–‡æ¡£
            print(f"ä½¿ç”¨åµŒå…¥å‘é‡æœç´¢ç›¸ä¼¼æ–‡æ¡£...")
            # ç¡®ä¿top_kå’Œdocumentsé•¿åº¦éƒ½æ˜¯æ•´æ•°
            doc_count = len(self.documents)
            safe_top_k = min(top_k, doc_count) if isinstance(doc_count, int) else top_k
            
            if safe_top_k <= 0 or doc_count <= 0:
                print("âš ï¸ æ–‡æ¡£æ•°é‡ä¸º0æˆ–top_kè®¾ç½®é”™è¯¯ï¼Œè¿”å›ç©ºç»“æœ")
                return []
            
            # ç¡®ä¿æŸ¥è¯¢å‘é‡æ˜¯æ­£ç¡®çš„numpyæ•°ç»„æ ¼å¼
            try:
                query_vector = np.array([query_embedding], dtype=np.float32)
                
                if self.index.ntotal == 0:
                    print("âš ï¸ ç´¢å¼•ä¸ºç©ºï¼Œè¿”å›ç©ºç»“æœ")
                    return []
                    
                # æ‰§è¡Œæœç´¢
                D, I = self.index.search(query_vector, safe_top_k)
                
                # é˜²æ­¢ç´¢å¼•è¶Šç•Œ
                valid_indices = [i for i in I[0] if 0 <= i < len(self.documents)]
                results = [self.documents[i] for i in valid_indices]
                
                if not results:
                    print("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")
                    return []
                
            except Exception as e:
                print(f"âš ï¸ æœç´¢è¿‡ç¨‹å‡ºé”™: {str(e)}")
                return []
            
            # ä½¿ç”¨é›†åˆå»é‡
            unique_results = list(set(results))
            
            # å°†ç»“æœè½¬æ¢ä¸ºç»“æ„åŒ–æ ¼å¼ï¼ˆå¦‚æœæœ‰å®Œæ•´å¯¹è¯ï¼‰
            try:
                import re
                
                structured_results = []
                user_pattern = re.compile(r'^\[(.*?)\]å¯¹æ–¹\(ID:(.*?)\): (.*)$')
                ai_pattern = re.compile(r'^\[(.*?)\] ä½ : (.*)$')
                
                # å°è¯•å°†æ ‡å‡†æ–‡æœ¬æ ¼å¼ç»“æœè½¬ä¸ºæ–°çš„JSONç»“æ„
                for result in unique_results:
                    user_match = user_pattern.match(result)
                    ai_match = ai_pattern.match(result)
                    
                    if user_match:
                        # æŸ¥æ‰¾åŒ¹é…çš„AIå›å¤
                        timestamp, user_id, message = user_match.groups()
                        for other_result in unique_results:
                            ai_match = ai_pattern.match(other_result)
                            if ai_match and timestamp in other_result:
                                ai_timestamp, ai_response = ai_match.groups()
                                # åˆ›å»ºç»“æ„åŒ–ç»“æœ
                                structured_result = {
                                    "user_message": message.strip(),
                                    "ai_response": ai_response.strip(),
                                    "timestamp": timestamp.strip(),
                                    "user_id": user_id.strip()
                                }
                                structured_results.append(structured_result)
                                break
                
                # å¦‚æœæœ‰ç»“æ„åŒ–ç»“æœï¼Œè¿”å›è¿™äº›ç»“æœ
                if structured_results:
                    print(f"å·²å°†æŸ¥è¯¢ç»“æœè½¬æ¢ä¸º{len(structured_results)}æ¡ç»“æ„åŒ–è®°å¿†")
                    return structured_results
            except Exception as e:
                print(f"è½¬æ¢ä¸ºç»“æ„åŒ–æ ¼å¼å¤±è´¥: {str(e)}")
            
            # å¦‚æœéœ€è¦é‡æ’åº
            if rerank and self.reranker and len(unique_results) > 1:
                print(f"ä½¿ç”¨é‡æ’å™¨å¯¹ {len(unique_results)} ä¸ªç»“æœè¿›è¡Œæ’åº...")
                scores = self.reranker.rerank(query, unique_results)
                scored_results = list(zip(unique_results, scores))
                scored_results.sort(key=lambda x: x[1], reverse=True)
                unique_results = [r[0] for r in scored_results]
            
            print(f"RAGæŸ¥è¯¢: æ‰¾åˆ°{len(unique_results)}æ¡å»é‡ç»“æœï¼Œä»{len(results)}ä¸ªå€™é€‰ç»“æœä¸­")
            return unique_results
            
        except Exception as e:
            print(f"æŸ¥è¯¢è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            print(traceback.format_exc())
            return []

    def deduplicate_documents(self):
        """
        æ¸…ç†ç´¢å¼•ä¸­çš„é‡å¤æ–‡æ¡£
        è¿™å°†é‡å»ºæ•´ä¸ªç´¢å¼•ï¼Œç¡®ä¿æ¯ä¸ªæ–‡æ¡£åªå‡ºç°ä¸€æ¬¡
        """
        if not self.documents:
            print("æ²¡æœ‰æ–‡æ¡£ï¼Œæ— éœ€å»é‡")
            return
        
        print(f"å¼€å§‹å»é‡ï¼Œå½“å‰æ–‡æ¡£æ•°: {len(self.documents)}")
        
        # è·å–å½“å‰æ–‡æ¡£å¹¶åˆ›å»ºè§„èŒƒåŒ–æ˜ å°„
        original_count = len(self.documents)
        
        # æ›´å¼ºçš„è§„èŒƒåŒ–å’Œå»é‡
        unique_docs = []
        seen_normalized = set()
        
        for doc in self.documents:
            # åˆ›å»ºè§„èŒƒåŒ–ç‰ˆæœ¬ï¼ˆç§»é™¤ç©ºæ ¼ã€æ ‡ç‚¹å¹¶è½¬ä¸ºå°å†™ï¼‰
            normalized = re.sub(r'\s+', '', doc.lower())
            normalized = re.sub(r'[^\w\s]', '', normalized)
            
            if normalized not in seen_normalized:
                seen_normalized.add(normalized)
                unique_docs.append(doc)
            else:
                print(f"æ‰¾åˆ°é‡å¤æ–‡æ¡£: {doc[:50]}...")
        
        new_count = len(unique_docs)
        
        if original_count == new_count:
            print("æ²¡æœ‰å‘ç°é‡å¤æ–‡æ¡£")
            return
        
        print(f"å‘ç°{original_count - new_count}ä¸ªé‡å¤æ–‡æ¡£ï¼Œæ­£åœ¨é‡å»ºç´¢å¼•...")
        
        # é‡ç½®å½“å‰ç´¢å¼•å’Œæ–‡æ¡£
        self.documents = []
        if self.index:
            dim = self.index.d
            self.index = faiss.IndexFlatL2(dim)
        
        # é‡æ–°æ·»åŠ å»é‡åçš„æ–‡æ¡£
        for i, doc in enumerate(unique_docs):
            print(f"é‡æ–°æ·»åŠ æ–‡æ¡£ {i+1}/{len(unique_docs)}: {doc[:30]}...")
        
        # ä½¿ç”¨textså‚æ•°æ·»åŠ æ–‡æ¡£
        self.add_documents(texts=unique_docs)
        print(f"ç´¢å¼•é‡å»ºå®Œæˆï¼Œä»{original_count}ä¸ªæ–‡æ¡£å‡å°‘åˆ°{len(self.documents)}ä¸ªå”¯ä¸€æ–‡æ¡£")


def load_from_config(config_path: str = None) -> Optional[RAG]:
    if config_path is None:
        # è·å–å½“å‰æ–‡ä»¶çš„è·¯å¾„
        current_file = Path(__file__).resolve()
        # é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼ˆå‡è®¾ç»“æ„æ˜¯ é¡¹ç›®æ ¹ç›®å½•/src/memories/memory/core/rag.pyï¼‰
        root_dir = current_file.parents[4]
        
        # å°è¯•åœ¨å‡ ä¸ªå¸¸è§ä½ç½®æ‰¾åˆ°é…ç½®æ–‡ä»¶
        possible_paths = [
            os.path.join(root_dir, "src", "config", "rag_config.yaml"),
            os.path.join(root_dir, "src", "config", "config.yaml"),
            os.path.join(root_dir, "config.yaml"),
            os.path.join(root_dir, "config.yml"), 
            os.path.join(root_dir, "rag_config.yaml"),
            os.path.join(root_dir, "rag_config.yml"),
            os.path.join(root_dir, "memory_config.yaml"),
            os.path.join(root_dir, "memory_config.yml"),
            os.path.join(root_dir, "src", "config", "memory_config.yaml"),
            os.path.join(root_dir, "src", "memories", "config.yaml"),
            os.path.join(root_dir, "data", "memories", "config.yaml"),
            os.path.expanduser("~/.config/rag/config.yaml"),
            os.path.join(os.path.dirname(__file__), "config.yaml"),
        ]
        
        print(f"æ£€æŸ¥å¯èƒ½çš„é…ç½®æ–‡ä»¶è·¯å¾„:")
        for path in possible_paths:
            if os.path.exists(path):
                print(f"æ‰¾åˆ°é…ç½®æ–‡ä»¶: {path}")
                config_path = path
                break
            else:
                print(f"è·¯å¾„ä¸å­˜åœ¨: {path}")
                
        if config_path is None:
            print("âŒ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶")
            # åˆ›å»ºé»˜è®¤é…ç½®
            try:
                default_config_path = os.path.join(root_dir, "src", "config", "config.yaml")
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(default_config_path), exist_ok=True)
                print(f"åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {default_config_path}")
                create_default_config(default_config_path)
                if os.path.exists(default_config_path):
                    config_path = default_config_path
                    print(f"âœ… å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {default_config_path}")
                else:
                    print(f"âŒ æ— æ³•åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶")
                    return None
            except Exception as e:
                print(f"âŒ åˆ›å»ºé»˜è®¤é…ç½®å¤±è´¥: {str(e)}")
                return None
    
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return None
        
    try:
        import yaml
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            
        if not config:
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼æ— æ•ˆ: {config_path}")
            return None
            
        # æ£€æŸ¥æ˜¯å¦ä¸ºé¡¹ç›®é…ç½®æ–‡ä»¶ï¼ˆKouriChaté…ç½®ï¼‰ï¼Œå¦‚æœæ˜¯åˆ™è½¬æ¢æ ¼å¼
        if 'categories' in config and 'rag_settings' in config.get('categories', {}):
            print(f"æ£€æµ‹åˆ°KouriChaté¡¹ç›®é…ç½®æ–‡ä»¶ï¼Œè¿›è¡Œæ ¼å¼è½¬æ¢...")
            # è¿™é‡Œéœ€è¦å¯¼å…¥KouriChatçš„é…ç½®å¤„ç†æ¨¡å—
            try:
                # è·å–é¡¹ç›®æ ¹ç›®å½•
                project_root = Path(config_path).resolve().parents[2]
                sys.path.insert(0, str(project_root))
                
                try:
                    from src.memories.memory.examples.create_rag_config import extract_rag_settings, generate_rag_config
                    
                    # ä½¿ç”¨é¡¹ç›®é…ç½®åˆ›å»ºRAGé…ç½®
                    print(f"ä»é¡¹ç›®é…ç½®æå–RAGè®¾ç½®...")
                    rag_settings = extract_rag_settings(config)
                    config = generate_rag_config(rag_settings)
                    print(f"æˆåŠŸå°†é¡¹ç›®é…ç½®è½¬æ¢ä¸ºæ ‡å‡†RAGé…ç½®")
                    
                except ImportError as e:
                    print(f"å¯¼å…¥é…ç½®å¤„ç†æ¨¡å—å¤±è´¥: {str(e)}")
                    print(f"å°è¯•ä»åŸå§‹é…ç½®ä¸­æå–åŸºæœ¬å‚æ•°...")
                    
                    # å¦‚æœæ— æ³•å¯¼å…¥å¤„ç†æ¨¡å—ï¼Œè¿›è¡Œç®€å•çš„é…ç½®æå–
                    rag_settings = config.get('categories', {}).get('rag_settings', {}).get('settings', {})
                    
                    # è·å–embedding_modelï¼Œæ”¯æŒé”™è¯¯æ‹¼å†™çš„eembedding_model
                    embedding_model = rag_settings.get('embedding_model', {}).get('value', '')
                    if not embedding_model:
                        embedding_model = rag_settings.get('eembedding_model', {}).get('value', 'BAAI/bge-m3')
                    
                    # è·å–base_urlï¼Œæ”¯æŒé”™è¯¯æ‹¼å†™çš„bbase_url
                    base_url = rag_settings.get('base_url', {}).get('value', '')
                    if not base_url:
                        base_url = rag_settings.get('bbase_url', {}).get('value', 'https://api.siliconflow.cn/v1/embeddings')
                    
                    # åˆ›å»ºåŸºæœ¬é…ç½®
                    config = {
                        "singleton": True,
                        "environment": {
                            "disable_proxy": True,
                            "no_proxy": "*"
                        },
                        "embedding_model": {
                            "type": "siliconflow",
                            "model_name": embedding_model,
                            "api_key": rag_settings.get('api_key', {}).get('value', ""),
                            "api_url": base_url
                        }
                    }
                    
                    # å¤„ç†åµŒå…¥æ¨¡å‹URL
                    api_url = config['embedding_model']['api_url']
                    if api_url and not api_url.endswith('/embeddings'):
                        # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                        api_url = api_url.rstrip('/')
                        # æ·»åŠ embeddingsè·¯å¾„
                        api_url = f"{api_url}/embeddings"
                        config['embedding_model']['api_url'] = api_url
                        print(f"é¡¹ç›®é…ç½®è½¬æ¢ï¼šå·²è°ƒæ•´åµŒå…¥æ¨¡å‹URL: {api_url}")
                    
                    # æ·»åŠ é‡æ’åºå™¨é…ç½®
                    if rag_settings.get('is_rerank', {}).get('value', False):
                        rerank_url = rag_settings.get('base_url', {}).get('value', "https://api.siliconflow.cn/v1")
                        # å¤„ç†é‡æ’åºæ¨¡å‹URL
                        if rerank_url and not rerank_url.endswith('/rerank'):
                            # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                            rerank_url = rerank_url.rstrip('/')
                            # æ·»åŠ rerankè·¯å¾„
                            rerank_url = f"{rerank_url}/rerank"
                        
                        config["reranker"] = {
                            "type": "siliconflow_native",
                            "model_name": rag_settings.get('reranker_model', {}).get('value', 'BAAI/bge-reranker-v2-m3'),
                            "api_key": rag_settings.get('api_key', {}).get('value', ""),
                            "api_url": rerank_url
                        }
                        print(f"é¡¹ç›®é…ç½®è½¬æ¢ï¼šå·²è°ƒæ•´é‡æ’åºæ¨¡å‹URL: {rerank_url}")
                        
                    print(f"å·²ä»é¡¹ç›®é…ç½®ä¸­æå–åŸºæœ¬RAGå‚æ•°")
                    
            except Exception as e:
                print(f"å¤„ç†é¡¹ç›®é…ç½®æ—¶å‡ºé”™: {str(e)}")
                print(f"å°†å°è¯•ä½œä¸ºæ ‡å‡†RAGé…ç½®ç»§ç»­å¤„ç†...")
            
        # åº”ç”¨ç¯å¢ƒé…ç½®
        print(f"åº”ç”¨ç¯å¢ƒé…ç½®...")
        apply_environment_config(config)
            
        # è§£æåµŒå…¥æ¨¡å‹é…ç½®
        embedding_model = None
        if 'embedding_model' in config:
            emb_config = config['embedding_model']
            
            # å¤„ç†ç¯å¢ƒå˜é‡å¼•ç”¨
            if 'api_key' in emb_config:
                emb_config['api_key'] = expand_env_vars(emb_config['api_key'])
                
            model_type = emb_config.get('type', '').lower()
            
            if model_type == 'siliconflow':
                # å¤„ç†URLï¼Œç¡®ä¿åµŒå…¥æ¨¡å‹URLä»¥"/embeddings"ç»“å°¾
                api_url = emb_config.get('api_url', 'https://api.siliconflow.cn/v1/embeddings')
                if api_url and not api_url.endswith('/embeddings'):
                    # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                    api_url = api_url.rstrip('/')
                    # æ·»åŠ embeddingsè·¯å¾„
                    api_url = f"{api_url}/embeddings"
                    print(f"å·²è°ƒæ•´åµŒå…¥æ¨¡å‹URL: {api_url}")
                
                embedding_model = SiliconFlowEmbeddingModel(
                    model_name=emb_config.get('model_name', 'BAAI/bge-large-zh-v1.5'),
                    api_key=emb_config.get('api_key'),
                    api_url=api_url
                )
            elif model_type == 'openai':
                # å¤„ç†URLï¼Œç¡®ä¿åµŒå…¥æ¨¡å‹URLä»¥"/embeddings"ç»“å°¾
                base_url = emb_config.get('base_url')
                if base_url and not base_url.endswith('/embeddings'):
                    # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                    base_url = base_url.rstrip('/')
                    # æ·»åŠ embeddingsè·¯å¾„
                    base_url = f"{base_url}/embeddings"
                    print(f"å·²è°ƒæ•´åµŒå…¥æ¨¡å‹URL: {base_url}")
                
                embedding_model = OnlineEmbeddingModel(
                    model_name=emb_config.get('model_name', 'text-embedding-ada-002'),
                    api_key=emb_config.get('api_key'),
                    base_url=base_url
                )
            elif model_type == 'local':
                embedding_model = LocalEmbeddingModel(
                    model_path=emb_config.get('model_path', 'paraphrase-multilingual-MiniLM-L12-v2')
                )
            elif model_type == 'hybrid':
                # åˆ›å»ºä¸»è¦APIæ¨¡å‹
                if emb_config.get('api_type', '').lower() == 'siliconflow':
                    # å¤„ç†URLï¼Œç¡®ä¿åµŒå…¥æ¨¡å‹URLä»¥"/embeddings"ç»“å°¾
                    api_url = emb_config.get('api_url', 'https://api.siliconflow.cn/v1/embeddings')
                    if api_url and not api_url.endswith('/embeddings'):
                        # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                        api_url = api_url.rstrip('/')
                        # æ·»åŠ embeddingsè·¯å¾„
                        api_url = f"{api_url}/embeddings"
                        print(f"å·²è°ƒæ•´æ··åˆæ¨¡å‹(siliconflow)URL: {api_url}")
                    
                    api_model = SiliconFlowEmbeddingModel(
                        model_name=emb_config.get('model_name', 'BAAI/bge-large-zh-v1.5'),
                        api_key=emb_config.get('api_key'),
                        api_url=api_url
                    )
                else:
                    # å¤„ç†URLï¼Œç¡®ä¿åµŒå…¥æ¨¡å‹URLä»¥"/embeddings"ç»“å°¾
                    base_url = emb_config.get('base_url')
                    if base_url and not base_url.endswith('/embeddings'):
                        # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                        base_url = base_url.rstrip('/')
                        # æ·»åŠ embeddingsè·¯å¾„
                        base_url = f"{base_url}/embeddings"
                        print(f"å·²è°ƒæ•´æ··åˆæ¨¡å‹(openai)URL: {base_url}")
                    
                    api_model = OnlineEmbeddingModel(
                        model_name=emb_config.get('model_name', 'text-embedding-ada-002'),
                        api_key=emb_config.get('api_key'),
                        base_url=base_url
                    )
                
                # åˆ›å»ºæ··åˆæ¨¡å‹
                embedding_model = HybridEmbeddingModel(
                    api_model=api_model,
                    local_model_path=emb_config.get('local_model_path', 'paraphrase-multilingual-MiniLM-L12-v2'),
                    local_model_enabled=emb_config.get('local_model_enabled', False)
                )
                
        if embedding_model is None:
            print("âŒ åµŒå…¥æ¨¡å‹é…ç½®æ— æ•ˆ")
            return None
            
        # è§£æé‡æ’åºå™¨é…ç½®
        reranker = None
        if 'reranker' in config:
            rerank_config = config['reranker']
            
            # å¤„ç†ç¯å¢ƒå˜é‡å¼•ç”¨
            if 'api_key' in rerank_config:
                rerank_config['api_key'] = expand_env_vars(rerank_config['api_key'])
                
            rerank_type = rerank_config.get('type', '').lower()
            
            if rerank_type == 'siliconflow_native':
                # å¤„ç†URLï¼Œç¡®ä¿é‡æ’åºæ¨¡å‹URLä»¥"/rerank"ç»“å°¾
                api_url = rerank_config.get('api_url', 'https://api.siliconflow.cn/v1/rerank')
                if api_url and not api_url.endswith('/rerank'):
                    # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                    api_url = api_url.rstrip('/')
                    # æ·»åŠ rerankè·¯å¾„
                    api_url = f"{api_url}/rerank"
                    print(f"å·²è°ƒæ•´é‡æ’åºæ¨¡å‹URL: {api_url}")
                
                reranker = SiliconFlowNativeReRanker(
                    model_name=rerank_config.get('model_name', 'BAAI/bge-reranker-v2-m3'),
                    api_key=rerank_config.get('api_key'),
                    api_url=api_url,
                    top_n=rerank_config.get('top_n'),
                    return_documents=rerank_config.get('return_documents', False)
                )
            elif rerank_type == 'siliconflow':
                # å¤„ç†URLï¼Œç¡®ä¿é‡æ’åºæ¨¡å‹URLä»¥"/chat/completions"ç»“å°¾
                api_url = rerank_config.get('api_url', 'https://api.siliconflow.cn/v1/chat/completions')
                if api_url and not api_url.endswith('/chat/completions'):
                    # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                    api_url = api_url.rstrip('/')
                    # æ·»åŠ chat/completionsè·¯å¾„
                    api_url = f"{api_url}/chat/completions"
                    print(f"å·²è°ƒæ•´é‡æ’åºæ¨¡å‹URL: {api_url}")
                
                reranker = SiliconFlowReRanker(
                    model_name=rerank_config.get('model_name', 'glm-4'),
                    api_key=rerank_config.get('api_key'),
                    api_url=api_url
                )
            elif rerank_type == 'openai':
                # å¤„ç†URLï¼Œç¡®ä¿é‡æ’åºæ¨¡å‹URLä»¥"/chat/completions"ç»“å°¾
                base_url = rerank_config.get('base_url')
                if base_url and not base_url.endswith('/chat/completions'):
                    # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                    base_url = base_url.rstrip('/')
                    # æ·»åŠ chat/completionsè·¯å¾„
                    base_url = f"{base_url}/chat/completions"
                    print(f"å·²è°ƒæ•´é‡æ’åºæ¨¡å‹URL: {base_url}")
                
                reranker = OnlineCrossEncoderReRanker(
                    model_name=rerank_config.get('model_name', 'gpt-3.5-turbo'),
                    api_key=rerank_config.get('api_key'),
                    base_url=base_url
                )
            elif rerank_type == 'local':
                reranker = CrossEncoderReRanker(
                    model_path=rerank_config.get('model_path', 'cross-encoder/ms-marco-MiniLM-L-6-v2')
                )
                
        # åˆ›å»ºRAGç³»ç»Ÿ
        rag = RAG(
            embedding_model=embedding_model,
            reranker=reranker,
            singleton=config.get('singleton', True)
        )
        
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸­æœ‰é¢„åŠ è½½çš„æ–‡æ¡£
        if 'documents' in config and isinstance(config['documents'], list):
            rag.add_documents(texts=config['documents'])
            
        print(f"âœ… æˆåŠŸä»é…ç½®æ–‡ä»¶åŠ è½½RAGç³»ç»Ÿ: {config_path}")
        return rag
        
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

# ç¤ºä¾‹é…ç½®æ–‡ä»¶å†…å®¹
"""
ç¤ºä¾‹ config.yaml æ–‡ä»¶:

```yaml
# RAGç³»ç»Ÿé…ç½®
singleton: true  # æ˜¯å¦ä½¿ç”¨å•ä¾‹æ¨¡å¼

# ç¯å¢ƒé…ç½®
environment:
  disable_proxy: true  # æ˜¯å¦ç¦ç”¨ä»£ç†è®¾ç½®
  no_proxy: "*"  # ç¦ç”¨ä»£ç†çš„åŸŸåï¼Œ"*"è¡¨ç¤ºæ‰€æœ‰
  api_key: ${SILICONFLOW_API_KEY}  # APIå¯†é’¥ï¼Œå¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡
  encoding: "utf-8"  # æ–‡æœ¬ç¼–ç 
  default_timeout: 10.0  # é»˜è®¤APIè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# åµŒå…¥æ¨¡å‹é…ç½®
embedding_model:
  type: siliconflow  # å¯é€‰: siliconflow, openai, local, hybrid
  model_name: BAAI/bge-large-zh-v1.5
  api_key: ${SILICONFLOW_API_KEY}  # å¯ä»¥å¼•ç”¨ç¯å¢ƒå˜é‡
  api_url: https://api.siliconflow.cn/v1/embeddings
  
  # ä»…hybridç±»å‹éœ€è¦ä»¥ä¸‹é…ç½®
  # api_type: siliconflow  # ä¸»APIç±»å‹: siliconflowæˆ–openai
  # local_model_path: paraphrase-multilingual-MiniLM-L12-v2
  # local_model_enabled: false

# é‡æ’åºå™¨é…ç½®ï¼ˆå¯é€‰ï¼‰
reranker:
  type: siliconflow_native  # å¯é€‰: siliconflow_native, siliconflow, openai, local
  model_name: BAAI/bge-reranker-v2-m3
  api_key: ${SILICONFLOW_API_KEY}  # å¯ä»¥å¼•ç”¨ç¯å¢ƒå˜é‡
  api_url: https://api.siliconflow.cn/v1/rerank
  top_n: 10  # è¿”å›å‰Nä¸ªç»“æœï¼Œå¯é€‰
  return_documents: false  # æ˜¯å¦åœ¨ç»“æœä¸­è¿”å›æ–‡æ¡£å†…å®¹ï¼Œå¯é€‰

# é¢„åŠ è½½æ–‡æ¡£ï¼ˆå¯é€‰ï¼‰
# documents:
#   - è¿™æ˜¯ç¬¬ä¸€ç¯‡æ–‡æ¡£
#   - è¿™æ˜¯ç¬¬äºŒç¯‡æ–‡æ¡£
#   - è¿™æ˜¯ç¬¬ä¸‰ç¯‡æ–‡æ¡£
```
"""

# è¾…åŠ©å‡½æ•°ï¼šå¤„ç†ç¯å¢ƒå˜é‡å¼•ç”¨
def expand_env_vars(value):
    """å¤„ç†é…ç½®å€¼ä¸­çš„ç¯å¢ƒå˜é‡å¼•ç”¨
    ä¾‹å¦‚ ${SILICONFLOW_API_KEY} ä¼šè¢«æ›¿æ¢ä¸ºç¯å¢ƒå˜é‡çš„å€¼
    """
    if not isinstance(value, str):
        return value
        
    import re
    import os
    
    pattern = r'\${([A-Za-z0-9_]+)}'
    matches = re.findall(pattern, value)
    
    result = value
    for env_var in matches:
        env_value = os.environ.get(env_var, "")
        result = result.replace(f"${{{env_var}}}", env_value)
    
    return result

# ä»£ç†è®¾ç½®çš„è¾…åŠ©å‡½æ•°
def disable_proxy_settings():
    """ç¦ç”¨ä»£ç†è®¾ç½®ï¼Œé¿å…è¿æ¥é—®é¢˜"""
    if 'http_proxy' in os.environ:
        del os.environ['http_proxy']
    if 'https_proxy' in os.environ:
        del os.environ['https_proxy']
    if 'HTTP_PROXY' in os.environ:
        del os.environ['HTTP_PROXY']
    if 'HTTPS_PROXY' in os.environ:
        del os.environ['HTTPS_PROXY']
    
    # ç¦ç”¨requestsåº“çš„ç¯å¢ƒå˜é‡ä»£ç†
    os.environ['NO_PROXY'] = '*'
    
    return True

# é…ç½®å¤„ç†å‡½æ•°
def apply_environment_config(config):
    """åº”ç”¨ç¯å¢ƒé…ç½®"""
    if not config or 'environment' not in config:
        return
        
    env_config = config['environment']
    
    # å¤„ç†ä»£ç†è®¾ç½®
    if env_config.get('disable_proxy', True):
        disable_proxy_settings()
        
    # è®¾ç½®NO_PROXY
    if 'no_proxy' in env_config:
        os.environ['NO_PROXY'] = env_config['no_proxy']
        
    # å¤„ç†APIå¯†é’¥
    if 'api_key' in env_config:
        api_key = expand_env_vars(env_config['api_key'])
        if api_key:
            os.environ['SILICONFLOW_API_KEY'] = api_key
            
    # è®¾ç½®é»˜è®¤ç¼–ç 
    if 'encoding' in env_config:
        encoding = env_config['encoding']
        try:
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding=encoding, errors='replace')
            sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding=encoding, errors='replace')
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸º{encoding}: {str(e)}")
            
    return True

# åˆ›å»ºé…ç½®æ–‡ä»¶çš„å‡½æ•°
def create_default_config(output_path="rag_config.yaml"):
    """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
    default_config = {
        "singleton": True,
        "environment": {
            "disable_proxy": True,
            "no_proxy": "*",
            "api_key": "${SILICONFLOW_API_KEY}",
            "encoding": "utf-8",
            "default_timeout": 10.0
        },
        "embedding_model": {
            "type": "siliconflow",
            "model_name": "BAAI/bge-m3",
            "api_key": "${SILICONFLOW_API_KEY}",
            "api_url": "https://api.siliconflow.cn/v1/embeddings"  # ç¡®ä¿URLåŒ…å«/embeddingsç«¯ç‚¹
        },
        "reranker": {
            "type": "siliconflow_native",
            "model_name": "BAAI/bge-reranker-v2-m3",
            "api_key": "${SILICONFLOW_API_KEY}",
            "api_url": "https://api.siliconflow.cn/v1/rerank",  # ç¡®ä¿URLåŒ…å«/rerankç«¯ç‚¹
            "top_n": 5,
            "return_documents": False
        }
    }
    
    try:
        import yaml
        with open(output_path, 'w', encoding='utf-8') as f:
            # æ·»åŠ æ³¨é‡Š
            f.write("# RAGç³»ç»Ÿé…ç½®æ–‡ä»¶\n")
            f.write("# è‡ªåŠ¨ç”Ÿæˆçš„é»˜è®¤é…ç½®\n")
            date_str = time.strftime("%Y-%m-%d %H:%M:%S")
            f.write(f"# åˆ›å»ºæ—¶é—´: {date_str}\n\n")
            
            # å†™å…¥YAML
            yaml.dump(default_config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
            
        print(f"âœ… é»˜è®¤é…ç½®æ–‡ä»¶å·²åˆ›å»º: {output_path}")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»ºé…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return False

if __name__ == "__main__":
    """
    æµ‹è¯•RAGç³»ç»ŸåŠŸèƒ½çš„ä¸»æ¨¡å—
    å½“ç›´æ¥æ‰§è¡Œæ­¤æ–‡ä»¶æ—¶è¿è¡Œæµ‹è¯•
    """
    import argparse
    import os
    import sys
    from pathlib import Path

    # æ­£ç¡®è®¾ç½®Pythonæ¨¡å—å¯¼å…¥è·¯å¾„
    project_root = Path(__file__).resolve().parents[3]
    sys.path.insert(0, str(project_root))
    
    # è®¾ç½®å‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="æµ‹è¯•RAGç³»ç»ŸåŠŸèƒ½")
    parser.add_argument("--model_type", choices=["local", "openai", "siliconflow", "hybrid"], 
                        default="siliconflow", help="åµŒå…¥æ¨¡å‹ç±»å‹")
    parser.add_argument("--model_name", default="BAAI/bge-m3", 
                        help="æ¨¡å‹åç§°ï¼Œå¦‚'BAAI/bge-m3'æˆ–'text-embedding-3-small'")
    parser.add_argument("--api_url", default="https://api.siliconflow.cn/v1/embeddings", 
                        help="API URL")
    parser.add_argument("--config", help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæä¾›åˆ™ä¼˜å…ˆä½¿ç”¨é…ç½®æ–‡ä»¶")
    parser.add_argument("--create_config", action="store_true", help="åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶")
    parser.add_argument("--config_path", default="config.yaml", help="é…ç½®æ–‡ä»¶è¾“å‡ºè·¯å¾„")
    parser.add_argument("--top_k", type=int, default=3, help="è¿”å›çš„ç›¸ä¼¼æ–‡æ¡£æ•°é‡")
    parser.add_argument("--rerank", action="store_true", help="æ˜¯å¦ä½¿ç”¨é‡æ’åº")
    parser.add_argument("--no_disable_proxy", action="store_true", help="ä¸ç¦ç”¨ä»£ç†è®¾ç½®")
    args = parser.parse_args()
    
    print("===== RAGç³»ç»Ÿæµ‹è¯• =====")
    
    # åˆ›å»ºé…ç½®æ–‡ä»¶
    if args.create_config:
        create_default_config(args.config_path)
        print(f"è¯·ä¿®æ”¹é…ç½®æ–‡ä»¶åå†æ¬¡è¿è¡Œç¨‹åº")
        sys.exit(0)
    
    # å°è¯•åŠ è½½é…ç½®æ–‡ä»¶
    config_path = args.config
    if not config_path:
        # å°è¯•ä»é¡¹ç›®é…ç½®æ–‡ä»¶åŠ è½½
        project_config_paths = [
            os.path.join(str(project_root), "src", "config", "config.yaml"),
            os.path.join("src", "config", "config.yaml"),
            os.path.join(os.getcwd(), "src", "config", "config.yaml")
        ]
        
        for path in project_config_paths:
            if os.path.exists(path):
                print(f"å‘ç°é¡¹ç›®é…ç½®æ–‡ä»¶: {path}")
                try:
                    # å°è¯•å¯¼å…¥é…ç½®å¤„ç†æ¨¡å—
                    sys.path.insert(0, str(Path(path).parent.parent.parent))
                    try:
                        from src.memories.memory.examples.create_rag_config import load_project_config, extract_rag_settings, generate_rag_config
                        
                        # ä½¿ç”¨é¡¹ç›®é…ç½®åˆ›å»ºRAGé…ç½®
                        print(f"æ­£åœ¨ä»é¡¹ç›®é…ç½®åˆ›å»ºRAGé…ç½®...")
                        project_config = load_project_config(path)
                        rag_settings = extract_rag_settings(project_config)
                        rag_config = generate_rag_config(rag_settings)
                        
                        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶
                        import tempfile
                        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as tmp:
                            # å†™å…¥é…ç½®
                            import yaml
                            yaml.dump(rag_config, tmp, default_flow_style=False, allow_unicode=True)
                            tmp_path = tmp.name
                        
                        # ä½¿ç”¨ä¸´æ—¶é…ç½®æ–‡ä»¶
                        print(f"å·²åˆ›å»ºä¸´æ—¶RAGé…ç½®æ–‡ä»¶: {tmp_path}")
                        config_path = tmp_path
                        break
                    except ImportError as e:
                        print(f"å¯¼å…¥é…ç½®å¤„ç†æ¨¡å—å¤±è´¥: {str(e)}")
                        # å°è¯•ç›´æ¥ä½¿ç”¨è·¯å¾„
                        config_path = path
                        print(f"å°†ç›´æ¥ä½¿ç”¨é¡¹ç›®é…ç½®è·¯å¾„: {path}")
                        break
                except Exception as e:
                    print(f"å¤„ç†é¡¹ç›®é…ç½®æ—¶å‡ºé”™: {str(e)}")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¡¹ç›®é…ç½®ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤é…ç½®æ–‡ä»¶
        if not config_path:
            for default_path in ["config.yaml", "rag_config.yaml"]:
                if os.path.exists(default_path):
                    config_path = default_path
                    print(f"å°†ä½¿ç”¨é»˜è®¤é…ç½®æ–‡ä»¶: {config_path}")
                    break
    
    # å¦‚æœé…ç½®æ–‡ä»¶å­˜åœ¨ï¼Œå°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½
    if config_path and os.path.exists(config_path):
        print(f"\nä»é…ç½®æ–‡ä»¶åŠ è½½ç³»ç»Ÿ: {config_path}")
        rag = load_from_config(config_path)
        if rag:
            print("æˆåŠŸä»é…ç½®æ–‡ä»¶åŠ è½½RAGç³»ç»Ÿ")
        else:
            print("ä»é…ç½®æ–‡ä»¶åŠ è½½RAGç³»ç»Ÿå¤±è´¥ï¼Œå°†å°è¯•ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°")
            config_path = None
    else:
        config_path = None
        
    # å¦‚æœæ²¡æœ‰ç¦ç”¨ä»£ç†ä¸”æœªä»é…ç½®æ–‡ä»¶åŠ è½½ï¼Œæ‰‹åŠ¨ç¦ç”¨ä»£ç†
    if not args.no_disable_proxy and not config_path:
        disable_proxy_settings()
        print("å·²ç¦ç”¨ä»£ç†è®¾ç½®ï¼Œä»¥é¿å…è¿æ¥é—®é¢˜")
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.environ.get("SILICONFLOW_API_KEY")
    if not api_key:
        print("âš ï¸ è­¦å‘Š: æœªè®¾ç½®ç¯å¢ƒå˜é‡ SILICONFLOW_API_KEY")
        print("ç¤ºä¾‹: export SILICONFLOW_API_KEY='your_api_key_here'")
        api_key = input("è¯·è¾“å…¥APIå¯†é’¥ï¼ˆæˆ–ç›´æ¥æŒ‰Enterè·³è¿‡ï¼‰: ").strip()
        if api_key:
            os.environ["SILICONFLOW_API_KEY"] = api_key
    
    # æµ‹è¯•ç¤ºä¾‹æ–‡æ¡£
    test_docs = [
        "ç¡…åŸºæµåŠ¨æ˜¯ä¸€å®¶ä¸­å›½çš„AIæœåŠ¡æä¾›å•†ï¼Œä¸“æ³¨äºæä¾›é«˜è´¨é‡çš„APIæœåŠ¡ã€‚",
        "å‘é‡åµŒå…¥æŠ€æœ¯æ˜¯ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†çš„åŸºç¡€ï¼Œå¯ä»¥æ•æ‰æ–‡æœ¬çš„è¯­ä¹‰ä¿¡æ¯ã€‚",
        "æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯ç»“åˆäº†æ£€ç´¢ç³»ç»Ÿå’Œç”Ÿæˆå¼AIçš„ä¼˜åŠ¿ã€‚",
        "å¤§è¯­è¨€æ¨¡å‹éœ€è¦é€šè¿‡å¤–éƒ¨çŸ¥è¯†åº“æ‰©å±•å…¶çŸ¥è¯†èŒƒå›´å’Œèƒ½åŠ›ã€‚",
        "æ–‡æœ¬å‘é‡åŒ–æ˜¯å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºè®¡ç®—æœºå¯ç†è§£çš„æ•°å€¼è¡¨ç¤ºçš„è¿‡ç¨‹ã€‚"
    ]
    
    # åˆå§‹åŒ–RAGç³»ç»Ÿ
    try:
        # å¦‚æœå·²ç»ä»é…ç½®æ–‡ä»¶åŠ è½½äº†ç³»ç»Ÿï¼Œç›´æ¥ä½¿ç”¨
        if config_path and 'rag' in locals() and rag:
            pass
        # å¦åˆ™ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°åˆ›å»ºç³»ç»Ÿ
        else:
            # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°åˆ›å»ºåµŒå…¥æ¨¡å‹
            print(f"\nåˆ›å»º{args.model_type}ç±»å‹çš„åµŒå…¥æ¨¡å‹...")
            
            if args.model_type == "siliconflow":
                # æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦å…¼å®¹ç¡…åŸºæµåŠ¨API
                siliconflow_models = ["BAAI/bge-large-zh-v1.5", "BAAI/bge-m3", "BAAI/bge-base-zh-v1.5"]
                if args.model_name not in siliconflow_models:
                    print(f"âš ï¸ æ¨¡å‹åç§°'{args.model_name}'å¯èƒ½ä¸å…¼å®¹ç¡…åŸºæµåŠ¨APIï¼Œå°†ä½¿ç”¨BAAI/bge-m3")
                    model_name = "BAAI/bge-m3"
                else:
                    model_name = args.model_name
                
                # å¤„ç†URLï¼Œç¡®ä¿åµŒå…¥æ¨¡å‹URLä»¥"/embeddings"ç»“å°¾
                api_url = args.api_url
                if api_url and not api_url.endswith('/embeddings'):
                    # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                    api_url = api_url.rstrip('/')
                    # æ·»åŠ embeddingsè·¯å¾„
                    api_url = f"{api_url}/embeddings"
                    print(f"å·²è°ƒæ•´åµŒå…¥æ¨¡å‹URL: {api_url}")
                
                embedding_model = SiliconFlowEmbeddingModel(
                    model_name=model_name,
                    api_key=api_key,
                    api_url=api_url
                )
                
                # å¦‚æœéœ€è¦é‡æ’åºï¼Œåˆ›å»ºé‡æ’åºå™¨
                reranker = None
                if args.rerank:
                    print("åˆ›å»ºç¡…åŸºæµåŠ¨åŸç”Ÿé‡æ’åºå™¨...")
                    
                    # å¤„ç†URLï¼Œç¡®ä¿é‡æ’åºæ¨¡å‹URLä»¥"/rerank"ç»“å°¾
                    rerank_url = api_url.replace("/embeddings", "/rerank")
                    if not rerank_url.endswith('/rerank'):
                        # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                        rerank_url = rerank_url.rstrip('/')
                        # æ·»åŠ rerankè·¯å¾„
                        rerank_url = f"{rerank_url}/rerank"
                    print(f"é‡æ’åºæ¨¡å‹URL: {rerank_url}")
                    
                    reranker = SiliconFlowNativeReRanker(
                        model_name="BAAI/bge-reranker-v2-m3",
                        api_key=api_key,
                        api_url=rerank_url
                    )
            
            elif args.model_type == "openai":
                # å¤„ç†URLï¼Œç¡®ä¿åµŒå…¥æ¨¡å‹URLä»¥"/embeddings"ç»“å°¾
                base_url = args.api_url
                if base_url and not base_url.endswith('/embeddings'):
                    # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                    base_url = base_url.rstrip('/')
                    # æ·»åŠ embeddingsè·¯å¾„
                    base_url = f"{base_url}/embeddings"
                    print(f"å·²è°ƒæ•´åµŒå…¥æ¨¡å‹URL: {base_url}")
                
                embedding_model = OnlineEmbeddingModel(
                    model_name=args.model_name,
                    api_key=api_key,
                    base_url=base_url
                )
                
                # å¦‚æœéœ€è¦é‡æ’åºï¼Œåˆ›å»ºé‡æ’åºå™¨
                reranker = None
                if args.rerank:
                    print("åˆ›å»ºåœ¨çº¿é‡æ’åºå™¨...")
                    
                    # å¤„ç†URLï¼Œç¡®ä¿é‡æ’åºæ¨¡å‹URLä»¥"/chat/completions"ç»“å°¾
                    chat_url = base_url.replace("/embeddings", "/chat/completions")
                    if not chat_url.endswith('/chat/completions'):
                        # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                        chat_url = chat_url.rstrip('/')
                        # æ·»åŠ chat/completionsè·¯å¾„
                        chat_url = f"{chat_url}/chat/completions"
                    print(f"é‡æ’åºæ¨¡å‹URL: {chat_url}")
                    
                    reranker = OnlineCrossEncoderReRanker(
                        model_name="gpt-3.5-turbo",
                        api_key=api_key,
                        base_url=chat_url
                    )
                
            elif args.model_type == "local":
                # éªŒè¯æ¨¡å‹è·¯å¾„æˆ–æ¨¡å‹ID
                if not args.model_name:
                    model_name = "paraphrase-multilingual-MiniLM-L12-v2"
                    print(f"æœªæŒ‡å®šæœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å‹: {model_name}")
                else:
                    model_name = args.model_name
                
                embedding_model = LocalEmbeddingModel(model_path=model_name)
                
                # å¦‚æœéœ€è¦é‡æ’åºï¼Œåˆ›å»ºæœ¬åœ°é‡æ’åºå™¨
                reranker = None
                if args.rerank:
                    print("åˆ›å»ºæœ¬åœ°é‡æ’åºå™¨...")
                    reranker = CrossEncoderReRanker(model_path="cross-encoder/ms-marco-MiniLM-L-6-v2")
                
            elif args.model_type == "hybrid":
                # åˆ›å»ºAPIæ¨¡å‹
                print("åˆ›å»ºæ··åˆåµŒå…¥æ¨¡å‹...")
                if "siliconflow" in args.api_url.lower():
                    # ç¡…åŸºæµåŠ¨APIæ¨¡å‹
                    siliconflow_models = ["BAAI/bge-large-zh-v1.5", "BAAI/bge-m3", "BAAI/bge-base-zh-v1.5"]
                    if args.model_name not in siliconflow_models:
                        print(f"âš ï¸ æ¨¡å‹åç§°'{args.model_name}'å¯èƒ½ä¸å…¼å®¹ç¡…åŸºæµåŠ¨APIï¼Œå°†ä½¿ç”¨BAAI/bge-m3")
                        model_name = "BAAI/bge-m3"
                    else:
                        model_name = args.model_name
                    
                    # å¤„ç†URLï¼Œç¡®ä¿åµŒå…¥æ¨¡å‹URLä»¥"/embeddings"ç»“å°¾
                    api_url = args.api_url
                    if api_url and not api_url.endswith('/embeddings'):
                        # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                        api_url = api_url.rstrip('/')
                        # æ·»åŠ embeddingsè·¯å¾„
                        api_url = f"{api_url}/embeddings"
                        print(f"å·²è°ƒæ•´æ··åˆæ¨¡å‹(siliconflow)URL: {api_url}")
                    
                    api_model = SiliconFlowEmbeddingModel(
                        model_name=model_name,
                        api_key=api_key,
                        api_url=api_url
                    )
                else:
                    # OpenAI APIæ¨¡å‹
                    # å¤„ç†URLï¼Œç¡®ä¿åµŒå…¥æ¨¡å‹URLä»¥"/embeddings"ç»“å°¾
                    base_url = args.api_url
                    if base_url and not base_url.endswith('/embeddings'):
                        # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                        base_url = base_url.rstrip('/')
                        # æ·»åŠ embeddingsè·¯å¾„
                        base_url = f"{base_url}/embeddings"
                        print(f"å·²è°ƒæ•´æ··åˆæ¨¡å‹(openai)URL: {base_url}")
                    
                    api_model = OnlineEmbeddingModel(
                        model_name=args.model_name,
                        api_key=api_key,
                        base_url=base_url
                    )
                
                # åˆ›å»ºæ··åˆæ¨¡å‹
                embedding_model = HybridEmbeddingModel(
                    api_model=api_model,
                    local_model_path="paraphrase-multilingual-MiniLM-L12-v2",
                    local_model_enabled=True
                )
                
                # å¦‚æœéœ€è¦é‡æ’åºï¼Œåˆ›å»ºé‡æ’åºå™¨
                reranker = None
                if args.rerank:
                    if "siliconflow" in args.api_url.lower():
                        print("åˆ›å»ºç¡…åŸºæµåŠ¨åŸç”Ÿé‡æ’åºå™¨...")
                        
                        # å¤„ç†URLï¼Œç¡®ä¿é‡æ’åºæ¨¡å‹URLä»¥"/rerank"ç»“å°¾
                        rerank_url = api_url.replace("/embeddings", "/rerank")
                        if not rerank_url.endswith('/rerank'):
                            # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                            rerank_url = rerank_url.rstrip('/')
                            # æ·»åŠ rerankè·¯å¾„
                            rerank_url = f"{rerank_url}/rerank"
                        print(f"é‡æ’åºæ¨¡å‹URL: {rerank_url}")
                        
                        reranker = SiliconFlowNativeReRanker(
                            model_name="BAAI/bge-reranker-v2-m3",
                            api_key=api_key,
                            api_url=rerank_url
                        )
                    else:
                        print("åˆ›å»ºåœ¨çº¿é‡æ’åºå™¨...")
                        
                        # å¤„ç†URLï¼Œç¡®ä¿é‡æ’åºæ¨¡å‹URLä»¥"/chat/completions"ç»“å°¾
                        chat_url = base_url.replace("/embeddings", "/chat/completions")
                        if not chat_url.endswith('/chat/completions'):
                            # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
                            chat_url = chat_url.rstrip('/')
                            # æ·»åŠ chat/completionsè·¯å¾„
                            chat_url = f"{chat_url}/chat/completions"
                        print(f"é‡æ’åºæ¨¡å‹URL: {chat_url}")
                        
                        reranker = OnlineCrossEncoderReRanker(
                            model_name="gpt-3.5-turbo",
                            api_key=api_key,
                            base_url=chat_url
                        )
            
            # åˆ›å»ºRAGç³»ç»Ÿ
            print("åˆ›å»ºRAGç³»ç»Ÿ...")
            rag = RAG(embedding_model=embedding_model, reranker=reranker)
        
        # æµ‹è¯•åµŒå…¥æ¨¡å‹
        print("\n===== æµ‹è¯•åµŒå…¥æ¨¡å‹ =====")
        test_text = "æµ‹è¯•åµŒå…¥æ¨¡å‹çš„æ€§èƒ½"
        try:
            print(f"åµŒå…¥æµ‹è¯•æ–‡æœ¬: '{test_text}'")
            embedding = rag.embedding_model.embed([test_text])[0]
            if embedding and len(embedding) > 0:
                dim = len(embedding)
                print(f"âœ… åµŒå…¥æˆåŠŸ! åµŒå…¥ç»´åº¦: {dim}")
                
                # åˆå§‹åŒ–ç´¢å¼•
                print(f"ä½¿ç”¨ç»´åº¦ {dim} åˆå§‹åŒ–ç´¢å¼•...")
                rag.initialize_index(dim=dim)
            else:
                print("âŒ åµŒå…¥å¤±è´¥ï¼Œæ— æ³•è·å–æœ‰æ•ˆçš„åµŒå…¥å‘é‡")
                sys.exit(1)
        except Exception as e:
            print(f"âŒ åµŒå…¥æµ‹è¯•å¤±è´¥: {str(e)}")
            print("å°è¯•ä½¿ç”¨é»˜è®¤ç»´åº¦åˆå§‹åŒ–ç´¢å¼•...")
            rag.initialize_index(dim=1024)
        
        # æ·»åŠ æµ‹è¯•æ–‡æ¡£
        print(f"\n===== æ·»åŠ æµ‹è¯•æ–‡æ¡£ =====")
        print(f"æ·»åŠ {len(test_docs)}ä¸ªæ–‡æ¡£...")
        rag.add_documents(texts=test_docs)
        print(f"å½“å‰æ–‡æ¡£æ•°é‡: {len(rag.documents)}")
        print(f"ç´¢å¼•å¤§å°: {rag.index.ntotal}")
        
        # æµ‹è¯•æŸ¥è¯¢
        print(f"\n===== æµ‹è¯•æŸ¥è¯¢ =====")
        while True:
            query = input("\nè¯·è¾“å…¥æŸ¥è¯¢å†…å®¹ï¼ˆæˆ–è¾“å…¥qé€€å‡ºï¼‰: ").strip()
            if query.lower() in ['q', 'quit', 'exit']:
                break
            
            if not query:
                continue
                
            print(f"æŸ¥è¯¢: '{query}'")
            try:
                start_time = time.time()
                results = rag.query(
                    query=query, 
                    top_k=args.top_k, 
                    rerank=args.rerank,
                    async_mode=True  # ä½¿ç”¨å¼‚æ­¥æ¨¡å¼åŠ é€Ÿ
                )
                query_time = time.time() - start_time
                
                if results and len(results) > 0:
                    print(f"âœ… æŸ¥è¯¢æˆåŠŸ! æ‰¾åˆ°{len(results)}ä¸ªç›¸å…³æ–‡æ¡£ (ç”¨æ—¶: {query_time:.3f}ç§’):")
                    for i, doc in enumerate(results):
                        print(f"[{i+1}] {doc}")
                else:
                    print("âŒ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
            except Exception as e:
                print(f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}")
        
        # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
        if hasattr(rag.embedding_model, "get_cache_stats"):
            cache_stats = rag.embedding_model.get_cache_stats()
            print("\n===== ç¼“å­˜ç»Ÿè®¡ =====")
            print(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_stats.get('hit_rate_percent', 0):.2f}%")
            print(f"ç¼“å­˜å¤§å°: {cache_stats.get('cache_size', 0)} æ¡ç›®")
        
        print("\næµ‹è¯•å®Œæˆï¼Œæ„Ÿè°¢ä½¿ç”¨!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
